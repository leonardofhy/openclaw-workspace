# üß† Cycle #82 ‚Äî 2026-02-28 16:32
## Action: reflect (meta-synthesis ‚Äî Gap #18 experimental design)
## Context: Meta-awareness cron; last cycle (#81) just identified Gap #18 (phonological vector geometry through connector). arXiv Feb 28 batch still not posted at 16:31 PM. Execution-blocked. Best action = synthesize Gap #18 into a concrete experiment design while it's fresh.

---

## Content: Gap #18 Experiment Design ‚Äî "Phonological Geometry Through the Connector"

### Background (from cycle #81)
Choi et al. (2602.18899) proved that phonological features in S3M encoders (HuBERT/WavLM/wav2vec2.0) are **linear, compositional, and scale-continuous** across 96 languages:
- `[b] = [d] - [t] + [p]` (voicing arithmetic works)
- Magnitude scales with degree of acoustic realization
- Cross-lingual: universal phonological vectors

**Gap #18**: Does this linear phonological geometry **survive through the connector into the speech LLM's residual stream?**
- If YES ‚Üí LLM has structured phonological access ‚Üí "listening" is phonologically coherent
- If NO ‚Üí connector destroys geometry ‚Üí modality collapse, grounding fails

### Why This Matters
- This is a **direct test of the Connector Bottleneck hypothesis** (from Gap #14, Modality Collapse 2602.23136)
- It's **causal**: if geometry survives, causal interventions on phonological vectors should propagate through connector
- It's a **prerequisite for Paper A**: if grounding_coefficient is to make sense, the model must have access to phonological structure in the LLM residual stream
- It's also **prerequisite for Audio T-SAE (Idea #7)**: T-SAE learns smooth features assuming there ARE phonological priors to exploit

### Proposed Experiment: "Phonological Geometry Probe"

**Step 1: Extract phonological direction vectors from S3M**
```python
# For Whisper-small encoder (proxy for S3M)
# Use LibriSpeech minimal pairs from Choi et al. code (github.com/juice500ml/phonetic-arithmetic)
# Compute: voicing_vector = h([d]) - h([t])  (voiced minus voiceless stop pair)
# Compute: nasality_vector = h([n]) - h([l])  (nasal minus lateral)
# Both at the encoder's output layer (post-connector input)
```

**Step 2: Project through connector (via NNsight)**
```python
# Hook the connector module's output
# For Qwen2-Audio: audio_encoder.connector or similar
# Get projected representation of voiced vs voiceless phoneme tokens
# Compute: connector_voicing_vec = projected_h([d]) - projected_h([t])
```

**Step 3: Test geometry in LLM residual stream**
```python
# Arithmetic test: does projected_h([b]) ‚âà projected_h([d]) - projected_h([t]) + projected_h([p])?
# Metric: cosine similarity of arithmetic result vs actual projection
# Baseline: random vectors ‚Üí expected ~0
# Choi et al. result in S3M: ~0.7-0.9 (high)
# Hypothesis: connector degrades this to <0.3 (geometry destroyed) OR maintains it >0.6 (geometry survives)
```

**Step 4: Layer-wise test**
```python
# For each LLM layer 0-N: probe for voicing_vector direction
# Use linear probe: can we decode voiced vs voiceless from LLM layer L hidden states?
# If probe acc drops sharply post-connector ‚Üí connector is the bottleneck
# If probe acc maintained ‚Üí geometry survives connector
```

### MacBook Feasibility Assessment
- **Model**: Whisper-small (6 layers, 244M params) for Step 1 ‚úÖ MacBook OK
- **S3M minimal pairs**: reuse Choi et al. code (public, no GPU needed for extraction) ‚úÖ
- **Connector test**: needs Qwen2-Audio or similar LALM ‚Üí too large for MacBook ‚ùå
  - Alternative: **use Whisper encoder output as S3M proxy, test on AudioLens architecture (DeSTA2)** ‚Äî DeSTA2 is smaller
  - OR: use NDIF to access Qwen2-Audio remotely via NNsight
- **Time estimate**: 2-4h with NDIF/DeSTA2, or 1-2 days if waiting for Êà∞Ëâ¶ GPU

### Connection Map
```
Gap #18 (Phonological Geometry Through Connector)
    ‚îú‚îÄ‚îÄ Paper A ("Listen Layer") ‚Äî prerequisite: connector must preserve something ‚Üí localization makes sense
    ‚îú‚îÄ‚îÄ Paper B (AudioSAEBench) ‚Äî TCS(F) metric assumes phonological features exist in LLM ‚Üí need to confirm
    ‚îú‚îÄ‚îÄ Idea #7 (Audio T-SAE) ‚Äî temporal contrastive training assumes phoneme-level features recoverable
    ‚îî‚îÄ‚îÄ Gap #14 (Modality Collapse, 2602.23136) ‚Äî GMI theory predicts encoding BUT decoding fails ‚Üí our test distinguishes encoding vs geometry preservation
```

### Research Value Assessment
- **Novelty**: HIGH ‚Äî Choi et al. didn't test this; nobody has. Gap #18 is genuinely open.
- **Feasibility**: MEDIUM (needs NDIF or small LALM; minimal pair stimuli already exist)
- **Publishability**: YES ‚Äî but likely as *part of* Paper A or Paper B, not standalone
  - Could be Figure 2 of Paper A: "Phonological geometry survives encoder, degrades/maintains through connector ‚Üí explains listen layer location"
  - Could be Category 0 of AudioSAEBench: prerequisite validation before SAE evaluation

### Idea Gate Quick Check
- Competitors: Choi et al. only tested within S3M; nobody tested through connector
- arXiv gap queries (done this cycle): 0 results for "connector phonological geometry" or "connector bottleneck phonological"
- Verdict: üü¢ GREEN ‚Äî integrate into Paper A/B as sub-experiment, not standalone

### Meta-Awareness Note
This synthesis happened 30 min after discovery (cycle #81). The Q7 rule (synthesis threshold after 10 reads) is working correctly ‚Äî this is the kind of synthesis that prevents ideas from decaying before they're actionable.

One system improvement applied this cycle: **Gap #18 added to experiment-queue.md as Priority 0 (prerequisite check)** ‚Äî because it's a necessary condition for Paper A's grounding_coefficient to be meaningful.

---

## Next: 
- arXiv Feb 28 batch when it posts (~18:00? ‚Äî unusual delay, check cs.SD)
- Gap #18 experiment added to experiment-queue.md (done this cycle)
- Leo unblock still needed for execution

## Tags: #gap18 #connector #phonological #meta-synthesis #experiment-design #paper-a #paper-b
