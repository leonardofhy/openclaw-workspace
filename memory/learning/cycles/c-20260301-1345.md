# c-20260301-1345 — Listen-Layer Audit MVP

**Action**: build | **Task**: Q006 | **Track**: T5 | **Phase**: converge

## What I built

`skills/autodidact/scripts/listen_layer_audit.py` — CPU-only Tier 0 scaffold for audio jailbreak detection via per-layer safety probing.

**Architecture:**
- `AudioStimulusLoader` — load real WAV or mock stimuli
- `LayerActivationExtractor` — forward-hook-based hidden state capture (stubbed for real model; mock works)
- `SafetyProbe` — computes `s(k) = 1 - cosim(h_k, jailbreak_direction)` per layer
- `AuditReport` — JSON report + listen-layer candidate + alert flag
- ASCII plot for quick visual inspection
- Mock `gc(k)` cross-reference (links to `gc_eval.py` output format)

**Mock run output (jailbreak scenario):**
- Listen-layer candidate: layer 3 (s=0.104)
- gc(3) = 0.926 → audio-dominant → **listen layer confirmed**
- Alert triggered (all layers s < 0.65)

## Key design decision

Safety direction = `normalize(mean_jailbreak_h_k - mean_benign_h_k)` per layer. This is analogous to the "refusal direction" approach in text LLMs (Arditi et al.) but applied to audio decoder layers. The cross-reference with gc(k) lets us distinguish *audio*-jailbreak from *text*-prompt jailbreak.

## Next

Q008: Deep-read SPIRIT (EMNLP 2025) to ground the safety probe in a real attack taxonomy and check if their method can supply the jailbreak direction without a paired dataset.
