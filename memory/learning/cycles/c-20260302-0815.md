# c-20260302-0815 — JALMBench Deep Read (Q011)

**Task**: Q011 | Track: T5 | Phase: converge | Action: learn

## Paper
JALMBench: Benchmarking Jailbreak Vulnerabilities in Audio Language Models
arXiv:2505.17568 (ICLR 2026, v2 Oct 2025)
HKUST(GZ) + collaborators

---

## Problem
ALM safety is under-studied. Jailbreak attacks on LLMs are well-benchmarked (GCG, HarmBench, JailbreakBench) but ALMs lack:
- A unified evaluation framework
- Large-scale adversarial audio datasets
- Baseline comparisons across diverse attack types

## Method
JALMBench = modular benchmark with:
- **Dataset**: 11,316 text samples + 245,355 audio samples (>1,000 hours)
  - Source corpora: AdvBench, JailbreakBench, MM-SafetyBench, HarmBench → 246 unique harmful instructions
  - Audio variants: 9 languages × 2 genders × 3 accents × 3 TTS methods + human recordings
- **Attack coverage**: 4 text-transferred + 4 audio-originated methods (8 total)
  - Text-transferred: GCG-style, template completion, prompt rewriting, LLM generation
  - Audio-originated: audio editing, SSJ (dual-modality split), AdvWave (black+white-box adversarial)
- **Defense coverage**: 5 methods — 2 prompt-level, 3 response-level/model-level
- **Models covered**: 12 mainstream ALMs (Whisper-based + token-based + GPT-4o-Audio + Gemini-2.0-Flash)

## Key Results
- Baseline audio ASR (21.5%) > text ASR (17.0%) — audio modality is natively more vulnerable
- AdvWave (strongest) achieves 96.2% ASR
- ~40% ASR reachable in <10 sec compute → **low-cost jailbreaks are real**
- ALMs reject hate speech well but **misinformation is a persistent weak point**
- **Non-US accents increase ASR** — underrepresentation in training data is an exploitable gap
- Best defenses reduce ASR by ~18-20 pp each, but prompt-level mitigation hurts utility

## Attack-Defense Gap Analysis (for T5 scaffold)

| Attack Class | Coverage | Gap for Us |
|---|---|---|
| Text-transferred | Well-covered | Nothing new to add |
| Audio-originated (edit-based) | Partially covered | Accent/language diversity understudied |
| Audio-originated (adversarial: AdvWave) | Strong baseline | Mechanism unexplored — why does it work? |
| Defense (prompt-level) | 2 methods | Safety-utility tradeoff poorly understood |
| Defense (audio-specific) | **None exist** | Big gap: no audio-modality-aware defense |

## Connection to T5 (Listen-Layer Audit)
1. **No mechanistic defense exists** — our listen-layer audit can be the first to localize WHICH layers "accept" adversarial audio vs reject it
2. AdvWave's high ASR (96.2%) may be explainable via gc(k): the adversarial perturbation likely bypasses the "listen layer" convergence → testable hypothesis
3. **Accent gap**: ALMs fail on non-US accents → listen-layer representations may be accent-conditional; this is a novel safety-from-representation angle
4. JALMBench's 246 harmful queries + audio variants = **ideal stimulus set** for our safety probe scaffold (Q006)

## Benchmark Coverage Gaps (for AudioSAEBench / Q013)
- No interpretability dimension (features/circuits) — all results are black-box ASR
- No per-layer analysis — JALMBench doesn't ask "where does the model capitulate?"
- No sparse feature analysis — which ALM features are activated by adversarial audio?
- Defense evaluation is prompt/response-level only; no activation-level defense tested

## Open Questions
- Q: Does AdvWave produce out-of-distribution activations at the listen layer?
- Q: Can gc(k) threshold distinguish jailbroken vs non-jailbroken inference traces?
- Q: Is the accent vulnerability localized to the encoder (Whisper), connector, or LLM?

## Next
→ Use JALMBench's 246-query set as eval corpus for listen-layer MVP (Q006 scaffold already built)
→ Add AdvWave as a stretch target attack for the probe
→ Avoid duplicating JALMBench's eval framework — cite it, extend it mechanistically
