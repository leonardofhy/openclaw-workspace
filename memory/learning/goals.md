# ğŸ¯ Autodidact Goals

> Last updated: 2026-02-26 14:45 by Leo (direct feedback)

## åŒ—æ¥µæ˜Ÿ (North Star)

**æˆç‚º Google DeepMind / Anthropic ç­‰ç´šçš„ AI Researcherã€‚**

### Thesis-level north star
> å»ºç«‹ä¸€å¥—å¯é©—è­‰çš„ audio æ©Ÿåˆ¶å–®å…ƒï¼ˆfeatures/circuitsï¼‰ï¼Œä¸¦ç”¨å®ƒå€‘åœ¨ ASR èˆ‡ audio-LLM ä¸­åŒæ™‚åšåˆ°ï¼š**å¯é å®šä½éŒ¯èª¤ä¾†æº + å¯æ§ä»‹å…¥æ”¹å–„è¡Œç‚ºï¼ˆå«å®‰å…¨/ç©©å¥æ€§ï¼‰**ã€‚

é€™å¥è©±ä¸²èµ·æ‰€æœ‰æ–¹å‘ï¼šSAEï¼ˆæ©Ÿåˆ¶å–®å…ƒï¼‰ã€patchingï¼ˆå¯é©—è­‰ï¼‰ã€ASRï¼ˆå¯é‡åŒ–è¡Œç‚ºï¼‰ã€audio-LLMï¼ˆèåˆèˆ‡å®‰å…¨ï¼‰ã€ä»¥åŠã€Œæ”¹å¾—å‹•ã€ã€‚

## ç•¶å‰ç ”ç©¶æ–¹å‘

### ä¸»æ–¹å‘ï¼šMechanistic Interpretability Ã— Speech/Multimodal LM
- **ç‚ºä»€éº¼é¸é€™å€‹**: é ˜åŸŸæ—©æœŸåŠ é€Ÿä¸­ï¼ˆ~20 ç¯‡ç›¸é—œå·¥ä½œï¼‰ï¼Œå…ˆé€²è€…å„ªå‹¢ä»åœ¨ä½†éœ€åŠ é€Ÿ
- **æ ¸å¿ƒå•é¡Œ**: Multimodal LMï¼ˆQwen-Audio, Gemini, GPT-4oï¼‰å¦‚ä½•åœ¨å…§éƒ¨è™•ç† speechï¼Ÿ
  - Speech tokens åœ¨å“ªä¸€å±¤è¢«è½‰åŒ–ç‚ºèªç¾©ï¼Ÿ
  - Emotion / speaker identity / phonetics åˆ†åˆ¥åœ¨å“ªè£¡è™•ç†ï¼Ÿ
  - Speech pathway å’Œ text pathway åœ¨å“ªè£¡äº¤æœƒï¼Ÿ
- **æ–¹æ³•è«–éœ€æ±‚**: activation patching, probing, SAE, logit lens â€” éœ€è¦å¾ text mech interp é·ç§»åˆ° speech

### æ¬¡æ–¹å‘ï¼šAI Safety Ã— Speech
- Audio adversarial attacks çš„æ©Ÿåˆ¶
- Speech-based jailbreak detection
- Speech modality æ˜¯å¦ç¹¼æ‰¿äº† text safety trainingï¼Ÿ

### é€²è¡Œä¸­ï¼šAudioMatters â€” Interspeech 2026
- ä¸€ä½œï¼ŒCMT å¡ä½æˆªæ­¢ 2026-02-26 19:00
- æœ€çµ‚ PDF 2026-03-05
- æŠ•ç¨¿å¾Œ â†’ æ³¨æ„åŠ›è½‰å‘ mech interp æ–¹å‘

## 5 Research Tracksï¼ˆä¸€å€‹ thesis çš„ä¸åŒåˆ‡é¢ï¼‰

**æˆ°ç•¥è€ƒé‡ï¼šAudioLens æ˜¯æ™ºå‡±å“¥çš„å·¥ä½œ â†’ Leo æœ‰ä¸»å ´å„ªå‹¢ï¼›5 tracks éƒ½æœå‹™åŒä¸€å€‹ thesis**

### Track 1ï¼šAudio Causal Benchmark / Protocol â†’ community resource
- å»ºç«‹ audio çš„ IOI â€” clean/corrupt æ¨™æº–ä»»å‹™ + patching protocol
- ç¬¬ä¸€ç¯‡ paper: 3-5 tasks (Speech Commands, ESC-50, çŸ­å¥ ASR) Ã— 3-5 corruptions
- **åšå‡ºä¾†æ‰€æœ‰äººå¼•ç”¨**

### Track 2ï¼šAudioSAE â†’ AudioSAEBench â†’ è©•ä¼°ç§‘å­¸åŒ–
- å° Whisper/HuBERT/WavLM åš SAE + audio-native è©•ä¼°æŒ‡æ¨™
- å› æœ steering/erasure æ¸¬è©¦ + å‰¯ä½œç”¨æ›²ç·š
- å»¶ä¼¸ï¼šfeature alignment across models/languages

### Track 3ï¼šListen vs Guess in Audio-LLMs â­ æœ€é«˜å„ªå…ˆ
- æ¥æ£’æ™ºå‡±å“¥ AudioLensï¼Œç”¨ minimal pairs + patching é‡åŒ– grounding
- å®šç¾© grounding coefficientï¼ˆaudio patching sensitivity vs context patching sensitivityï¼‰
- **å„ªå‹¢ï¼šæ™ºå‡±å“¥ = AudioLens ä½œè€… = æ¯å¤©ä¸€èµ·åƒé£¯çš„ labmateï¼Œå·²è«‡å¥½åˆä½œ**

### Track 4ï¼šMechanistic Interp of Adaptation (LoRA/adapters)
- è§£é‡‹ã€Œå¾®èª¿åˆ°åº•æ”¹äº†ä»€éº¼æ©Ÿåˆ¶ã€
- CKA/SVD + SAE drift + patching å®šä½è®ŠåŒ–
- å»¶ä¼¸ï¼šmechanistically guided fine-tuning

### Track 5ï¼šSafety Mechanistic Defenses
- Audio prompt injection benchmark + trigger subspace å®šä½
- æœ€å°å‰¯ä½œç”¨çš„ inference-time defense
- é¢¨éšªï¼šè² è²¬ä»»æ­éœ²ï¼Œdefense > attack

## 10 Core Research Questionsï¼ˆautodidact è®€è«–æ–‡æ™‚åœç¹é€™äº›å•é¡Œæ€è€ƒï¼‰
1. Audio çš„ "clean/corrupt" æ€éº¼è¨­è¨ˆæ‰åªç ´å£ä½ è¦éš”é›¢çš„å› ç´ ï¼Ÿ
2. Patching çš„ OOD internal state æ€éº¼è¨ºæ–·/é¿å…ï¼Ÿ
3. ASR çš„ WER æ˜¯åºåˆ—æŒ‡æ¨™ â€” æ€éº¼å°é½Šåˆ°å±€éƒ¨æ©Ÿåˆ¶ï¼Ÿ
4. SAE features èƒ½è·¨èªè¨€/å™ªè²/æ¨¡å‹é·ç§»å—ï¼Ÿç”¨ä»€éº¼ alignmentï¼Ÿ
5. Audio SAE è©•ä¼°è©²ç”¨ä»€éº¼æŒ‡æ¨™ï¼Ÿå“ªäº›èˆ‡ã€Œå¯å› æœæ“æ§ã€ç›¸é—œï¼Ÿ
6. æ¨¡å‹ä½•æ™‚åœ¨ã€Œè½ã€ã€ä½•æ™‚åœ¨ã€ŒçŒœã€ï¼Ÿæ€éº¼é‡åŒ–ï¼Ÿ
7. Connector bottleneck è®“å“ªäº›ä¿¡æ¯ä¸å¯é€†ä¸Ÿå¤±ï¼Ÿ
8. Audio jailbreak çš„ trigger subspace åœ¨ encoder é‚„æ˜¯ LMï¼Ÿ
9. Neural codec çš„ codebook åˆ†å·¥ â€” å“ªäº›å° pitch/timbre/æ¸…æ™°åº¦è² è²¬ï¼Ÿ
10. Audio èƒ½åšè‡ªå‹• circuit graph å—ï¼Ÿå‰ç½®æ¢ä»¶æ˜¯ä»€éº¼ï¼Ÿ

## Skill Gapsï¼ˆæŠ€èƒ½å±¤é¢ï¼‰
- [ ] TransformerLens + pyvene å¯¦ä½œ
- [ ] SAE è¨“ç·´ + evaluation discipline
- [ ] AudioLens codebaseï¼ˆå•æ™ºå‡±å“¥ï¼‰
- [ ] Whisper/HuBERT/WavLM é€å±¤æ©Ÿåˆ¶
- [ ] EnCodec discrete tokens èˆ‡ MI çš„æ¥å£
- [ ] Causal abstraction ç†è«–åŸºç¤

## Must-Read Listï¼ˆæŒ‰å„ªå…ˆç´šï¼‰
1. [ ] **AudioLens** (æ™ºå‡±å“¥ 2025, NTU) â€” lab è‡ªå·±çš„å·¥ä½œï¼[arXiv:2506.05140]
2. [x] **Beyond Transcription** (Glazer 2025) â€” ASR MI åŸºç¤æ–¹æ³•è«– [arXiv:2508.15882] âœ… 2026-02-26 deep read cycle #6
3. [ ] **AudioSAE** (Aparin 2026, EACL) â€” SAE for speech + steering [arXiv:2602.05027]
4. [ ] **Activation patching best practices** (Heimersheim & Nanda) â€” é¿å… pitfalls
5. [ ] **SPIRIT** (2025, EMNLP) â€” audio safety interventions [arXiv:2505.13541]
6. [ ] **Causal abstraction** (Geiger et al.) â€” å› æœä»‹å…¥çš„ç†è«–åŸºç¤
7. [ ] Multimodal MI Survey (Lin 2025) [arXiv:2502.17516]
8. [ ] **SAEBench** â€” SAE evaluation methodology
9. [ ] ICML 2025 MI Tutorial materials
10. [ ] **Interspeech 2025 Tutorial** â€” "Interpretability for Speech Models"ï¼ˆçµæ§‹åŒ–å…¥é–€ï¼‰

## 6-12 Month Ramp Plan
- **Month 0-2**: Foundations
  - ç²¾è®€ AudioLens + Beyond Transcription + AudioSAEï¼ˆæ–¹æ³•ç´°ç¯€ï¼Œä¸åª abstractï¼‰
  - TransformerLens + pyvene å¯¦ä½œï¼ˆå…ˆåœ¨ text ä¸Šè·‘é€šï¼Œå†é·ç§»åˆ° audioï¼‰
  - Starter experiments 1-3ï¼ˆprobing, CKA, Whisper neuron atlasï¼‰â†’ MacBook å¯è·‘
  - ç†è§£ patching pitfalls + SAE evaluation methodology
- **Month 2-4**: å’Œæ™ºå‡±å“¥åˆä½œè¨­è¨ˆ counterfactual experimentsï¼ˆå·²è«‡å¥½åˆä½œï¼‰
  - Starter experiments 4-5ï¼ˆsingle-layer SAE, intervention on Speech Commandsï¼‰â†’ æˆ°è‰¦
  - Define "clean vs corrupt" protocols for audio
- **Month 4-8**: è·‘å¯¦é©— + å¯«ç¬¬ä¸€ç¯‡è«–æ–‡
- **Month 8-12**: æŠ•ç¨¿ + é–‹å§‹ç¬¬äºŒå€‹æ–¹å‘

## Key Deadlines
| Conference | Deadline | Target Paper |
|-----------|----------|-------------|
| Interspeech 2026 | PDF 2026-03-05 | AudioMatters |
| NeurIPS 2026 | ~2026-05 | Listen vs Guess (if ready) |
| EMNLP 2026 | ~2026-06 | Audio InterpBench |

## ğŸ“Œ ç‹€æ…‹æ›´æ–° (2026-02-26 19:00)

**AudioMatters CMT deadline passed** â†’ Leo's focus now shifts fully to mech interp.

**Immediate next steps (post-deadline):**
1. Run `whisper_hook_demo.py` â€” verify toolchain works end-to-end
2. Extend hook demo with logit-lens projection â†’ run "Triple Convergence" experiment
3. Read SPIRIT (arXiv:2505.13541) â€” safety track anchor paper
4. Contact æ™ºå‡±å“¥ about AudioLens codebase access

**Recommended next cycle:** `build` â€” extend whisper_hook_demo.py with logit-lens projection to test Triple Convergence hypothesis. MacBook-feasible, ~2-3 hours.

## å¾…è«‹æ±‚ Leo çš„ä»»å‹™éšŠåˆ—
1. ğŸ”¬ **Deep Research**: Mech Interp Ã— Speech é ˜åŸŸæ·±åº¦æƒæï¼ˆå·²è«‹æ±‚ 2/26ï¼‰
2. ğŸ”§ **Deep Research**: è‡ªä¸» AI agent ç³»çµ±çš„å¯æŒçºŒæ¶æ§‹ï¼ˆå·²è«‹æ±‚ 2/26ï¼‰
