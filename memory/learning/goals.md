# ğŸ¯ Autodidact Goals

> Last updated: 2026-02-26 14:45 by Leo (direct feedback)

## åŒ—æ¥µæ˜Ÿ (North Star)

**æˆç‚º Google DeepMind / Anthropic ç­‰ç´šçš„ AI Researcherã€‚**

é€™æ„å‘³è‘—ï¼š
- åœ¨ NeurIPSã€ICMLã€ICLR ç­‰é ‚æœƒç™¼è¡¨æœ‰å½±éŸ¿åŠ›çš„å·¥ä½œï¼ˆè¢«å¼•ç”¨ã€è¢«è¨è«–ï¼‰
- èƒ½ç¨ç«‹è­˜åˆ¥æ·±å±¤çš„ç ”ç©¶å•é¡Œï¼Œè€Œéåªåš incremental improvement
- æŒæ¡ç´®å¯¦çš„æŠ€è¡“æ·±åº¦ï¼ˆä¸åªæ˜¯è®€è«–æ–‡ï¼Œè¦èƒ½å¾©ç¾ã€æ”¹é€²ã€æå‡ºæ–°æ–¹æ³•ï¼‰
- æ¸…æ™°æœ‰åŠ›çš„å­¸è¡“å¯«ä½œèƒ½åŠ›
- å…·å‚™ research taste â€” çŸ¥é“ä»€éº¼å•é¡Œå€¼å¾—èŠ± 6 å€‹æœˆå»è§£

é€™ä¸æ˜¯ä¸€å¹´èƒ½é”åˆ°çš„ç›®æ¨™ï¼Œä½†æ¯å€‹ cycle éƒ½æ‡‰è©²åœ¨å¾€é€™å€‹æ–¹å‘èµ°ã€‚

## ç•¶å‰ç ”ç©¶æ–¹å‘

### ä¸»æ–¹å‘ï¼šMechanistic Interpretability Ã— Speech/Multimodal LM
- **ç‚ºä»€éº¼é¸é€™å€‹**: arXiv ä¸Šåªæœ‰ 4 ç¯‡è«–æ–‡ï¼Œå¹¾ä¹ç©ºç™½ï¼Œå…ˆé€²è€…å„ªå‹¢å·¨å¤§
- **æ ¸å¿ƒå•é¡Œ**: Multimodal LMï¼ˆQwen-Audio, Gemini, GPT-4oï¼‰å¦‚ä½•åœ¨å…§éƒ¨è™•ç† speechï¼Ÿ
  - Speech tokens åœ¨å“ªä¸€å±¤è¢«è½‰åŒ–ç‚ºèªç¾©ï¼Ÿ
  - Emotion / speaker identity / phonetics åˆ†åˆ¥åœ¨å“ªè£¡è™•ç†ï¼Ÿ
  - Speech pathway å’Œ text pathway åœ¨å“ªè£¡äº¤æœƒï¼Ÿ
- **æ–¹æ³•è«–éœ€æ±‚**: activation patching, probing, SAE, logit lens â€” éœ€è¦å¾ text mech interp é·ç§»åˆ° speech

### æ¬¡æ–¹å‘ï¼šAI Safety Ã— Speech
- Audio adversarial attacks çš„æ©Ÿåˆ¶
- Speech-based jailbreak detection
- Speech modality æ˜¯å¦ç¹¼æ‰¿äº† text safety trainingï¼Ÿ

### é€²è¡Œä¸­ï¼šAudioMatters â€” Interspeech 2026
- ä¸€ä½œï¼ŒCMT å¡ä½æˆªæ­¢ 2026-02-26 19:00
- æœ€çµ‚ PDF 2026-03-05
- æŠ•ç¨¿å¾Œ â†’ æ³¨æ„åŠ›è½‰å‘ mech interp æ–¹å‘

## Paper Ideasï¼ˆåŸºæ–¼ 2026-02-26 deep research é‡æ–°æ’åºï¼‰

**æˆ°ç•¥è€ƒé‡ï¼šAudioLens æ˜¯æå®æ¯… lab çš„å·¥ä½œ â†’ Leo æœ‰ä¸»å ´å„ªå‹¢**

1. ğŸ¥‡ **"Listen vs Guess" â€” AudioLens å»¶ä¼¸** â†’ NeurIPS 2026 / ICLR 2027
   - æ¥æ£’ lab è‡ªå·±çš„ AudioLensï¼Œç”¨ controlled counterfactuals + patching é‡åŒ–ã€Œaudio evidence vs language priorã€
   - å®šç¾© "grounding coefficient"ï¼Œå› æœå®šä½ failure modes (encoder vs connector vs LM)
   - å„ªå‹¢ï¼šlab å…§æœ‰å‰äººåŸºç¤ã€æœ‰è€å¸«æŒ‡å°ã€æœ‰ GPU
   - é ä¼°ï¼š4-6 å€‹æœˆ

2. ğŸ¥ˆ **Audio InterpBench â€” MI çš„ evaluation benchmark** â†’ EMNLP 2026 / Interspeech
   - çµåˆ AudioMatters benchmark ç¶“é©— + MI æ–¹æ³•è«–
   - Synthetic ground-truth tasks with known causal structure
   - å„ªå‹¢ï¼šLeo çš„ evaluation å°ˆé•·ç›´æ¥é·ç§»
   - é ä¼°ï¼š3-4 å€‹æœˆ

3. ğŸ¥‰ **Audio Safety via MI (SPIRIT å»¶ä¼¸)** â†’ Workshop paper
   - Benchmark of audio jailbreak styles + mechanistic defenses comparison
   - æ¥æ£’ SPIRIT (EMNLP 2025)
   - å„ªå‹¢ï¼šAI Safety èˆˆè¶£ + NTUAIS ç¤¾ç¾¤
   - é ä¼°ï¼š2-3 å€‹æœˆ

## Knowledge Gaps
- [ ] TransformerLens activation patching å¯¦ä½œï¼ˆmonth 0-2 å¿…ä¿®ï¼‰
- [ ] SAE è¨“ç·´ + feature steeringï¼ˆAudioSAE å¾©ç¾ï¼‰
- [ ] AudioLens è«–æ–‡ç²¾è®€ + ä»£ç¢¼å¾©ç¾ï¼ˆ**lab å…§éƒ¨è³‡æº**ï¼‰
- [ ] Whisper / HuBERT encoder é€å±¤æ©Ÿåˆ¶
- [ ] Qwen2-Audio / SALMONN æ¶æ§‹
- [ ] ICML 2025 MI Tutorialï¼ˆçµæ§‹åŒ–å­¸ç¿’è·¯å¾‘ï¼‰

## Must-Read Listï¼ˆæŒ‰å„ªå…ˆç´šï¼‰
1. [ ] **AudioLens** (Yang 2025, NTU) â€” lab è‡ªå·±çš„å·¥ä½œï¼[arXiv:2506.05140]
2. [ ] **Beyond Transcription** (Glazer 2025) â€” ASR MI åŸºç¤æ–¹æ³•è«– [arXiv:2508.15882]
3. [ ] **AudioSAE** (Aparin 2026, EACL) â€” SAE for speech [arXiv:2602.05027]
4. [ ] **SPIRIT** (2025, EMNLP) â€” audio safety interventions [arXiv:2505.13541]
5. [ ] Multimodal MI Survey (Lin 2025) [arXiv:2502.17516]
6. [ ] ICML 2025 MI Tutorial materials

## 6-12 Month Ramp Plan
- **Month 0-2**: TransformerLens ç†Ÿç·´ + å¾©ç¾ AudioLens
- **Month 2-4**: åœ¨ AudioLens åŸºç¤ä¸Šè¨­è¨ˆ counterfactual experiments
- **Month 4-8**: è·‘å¯¦é©— + å¯«ç¬¬ä¸€ç¯‡è«–æ–‡
- **Month 8-12**: æŠ•ç¨¿ + é–‹å§‹ç¬¬äºŒå€‹æ–¹å‘

## Key Deadlines
| Conference | Deadline | Target Paper |
|-----------|----------|-------------|
| Interspeech 2026 | PDF 2026-03-05 | AudioMatters |
| NeurIPS 2026 | ~2026-05 | Listen vs Guess (if ready) |
| EMNLP 2026 | ~2026-06 | Audio InterpBench |

## å¾…è«‹æ±‚ Leo çš„ä»»å‹™éšŠåˆ—
1. ğŸ”¬ **Deep Research**: Mech Interp Ã— Speech é ˜åŸŸæ·±åº¦æƒæï¼ˆå·²è«‹æ±‚ 2/26ï¼‰
2. ğŸ”§ **Deep Research**: è‡ªä¸» AI agent ç³»çµ±çš„å¯æŒçºŒæ¶æ§‹ï¼ˆå·²è«‹æ±‚ 2/26ï¼‰
