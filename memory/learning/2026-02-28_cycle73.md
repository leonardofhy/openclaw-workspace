# ðŸ§  Cycle #73 â€” 2026-02-28 12:01
## Action: reflect (research priority synthesis)
## Context: 3 consecutive learn cycles (#70-72); forced reflect per SKILL.md rule. arXiv Feb 28 batch ~2h away (~14:00 Taipei). 7 paper ideas accumulated; no ranked priority document exists. This gap is itself a meta-problem: without a priority ranking, Leo and the system cannot make execution decisions. Synthesize now â€” high value, independent of Leo or arXiv.

---

## Content: 7-Idea Research Portfolio Priority Ranking

### Summary of All 7 Paper Ideas (as of cycle #72)

| # | Title Candidate | Track | Status |
|---|----------------|-------|--------|
| 1 | "Localizing the Listen Layer in Speech LLMs" (Paper A) | 3 | Full pitch âœ… |
| 2 | "AudioSAEBench: Multi-Metric Eval of SAEs for Speech/Audio LMs" (Paper B) | 2 | Full pitch âœ… |
| 3 | Track 3+4 Combined: "Causal AudioLens with LoRA" | 3+4 | Concept âœ… |
| 4 | "SAE-guided Inference-Time Safety Patching" (SPIRIT extension) | 5 | Concept âœ… |
| 5 | "Class-specific Neuron Grounding in LALMs" (Kawamura/Zhao extension) | 2+3 | Experiment sketch âœ… |
| 6 | "Audio Causal Benchmark / Protocol" (Audio IOI) | 1 | High-level concept |
| 7 | "Phoneme-Aware SAEs for Speech via Temporal Contrastive Learning" (Audio T-SAE) | 2.5 | Paper pitch concept âœ… |

---

### Priority Ranking (ordered by: impact Ã— feasibility Ã— timing Ã— competitive risk)

#### ðŸ¥‡ Priority 1: Paper A â€” "Localizing the Listen Layer in Speech LLMs"
**Why first:**
- Only 3h of MacBook experiments needed to validate core hypothesis (Triple Convergence IIT)
- Zero competitors: 5 papers measure listen/guess behaviorally (ALME, Cascade Equivalence, MiSTER-E, AR&D, Zhao) but NONE do layer-wise causal patching
- Field velocity ~2 papers/week â†’ window ~3-4 months before someone closes the gap
- Full pitch already written (`paper-a-pitch.md`)
- NNsight API assessed (better than pyvene), cheat sheet ready
- ALME provides 57K ready-to-use conflict stimuli (no need to generate own)
- NeurIPS 2026 deadline (~May 2026) = realistic if experiments start now

**Blockers:** Leo approval for IIT experiment + real speech .wav file + venv setup (15 min total)
**Next action:** Leo runs `python3 -m venv ~/audio-mi-env && pip install nnsight openai-whisper`

---

#### ðŸ¥ˆ Priority 2: Paper B â€” "AudioSAEBench"
**Why second:**
- Same metric (grounding_coefficient), same stimuli (ALME), same infrastructure as Paper A
- AR&D + AudioSAE + Mariotte = 3 existing SAEs to benchmark immediately
- Novel metrics: `gc(F)` (Grounding Sensitivity) + `TCS(F)` (Temporal Coherence) â€” zero competitors
- NeurIPS 2026 D&B track = perfect venue (community resource)
- Full pitch written (`paper-b-pitch.md`)

**Why not first:**
- Needs Paper A infra to work (same patching setup, reuses gc measurement)
- More ML engineering work (training/evaluating 3+ SAEs)
- Contribution is weaker without real experimental results in Paper A to validate gc(F)

**Strategic note:** Papers A and B share 60% of experimental setup. Do A first, then B. Total time savings ~2 months vs independent.

---

#### ðŸ¥‰ Priority 3: Audio T-SAE â€” "Phoneme-Aware SAEs for Speech via Temporal Contrastive Learning"
**Why third:**
- T-SAE is ICLR 2026 Oral â€” high visibility, guaranteed attention
- Authors explicitly flagged "sequential modalities" as future direction â†’ community expectation
- Audio T-SAE provides TCS(F) metric for Paper B = synergy
- No audio T-SAE paper exists (confirmed via arXiv search, cycle #72)
- Interspeech 2027 / ICASSP 2027 = realistic venue

**Why not higher:**
- Requires SAE training (GPU on the "warship" lab machine) â†’ needs more resources than MacBook-feasible Paper A
- Not MacBook-feasible until venv + real .wav experiments are done first
- Risk: T-SAE authors (Harvard/MIT) may self-extend to audio â€” move fast after Paper A
- Complements Papers A+B more than competes; better as 3rd paper in 12-month plan

**Competitive risk level: HIGH** â€” should aim to have a preprint out within 3 months.

---

#### 4th Priority: Idea #5 â€” "Class-specific Neuron Grounding in LALMs" (Kawamura + Zhao synthesis)
**Why this position:**
- Very strong scientific contribution (grounding_coefficient at neuron level)
- AAPE method + MAD/CAS selectors are already described in deep reads â€” minimal new methodology
- But requires LALM-scale experiments (Qwen2.5-Omni, Kimi-Audio) â†’ needs GPU
- Zhao et al. (Jan 2026) are recent, not yet cited much â†’ clean priority claim
- Can be combined with Paper A's patching infrastructure

**Relationship to others:** This IS a sharpening of Paper A's core question. Consider: either (a) make this Section 4 of Paper A ("neuron-level grounding"), or (b) standalone 2nd paper in Track 3.

---

#### 5th Priority: Idea #3 â€” "Causal AudioLens with LoRA"
**Why this position:**
- Strong contribution: closes gap in BOTH AudioLens AND "Behind the Scenes" (dual literature contribution)
- NNsight code in "Behind the Scenes" = reproducible starting point
- But requires LoRA training + Whisper-large (not MacBook-feasible for training)
- More engineering-heavy; idea is solid but execution risk higher
- Track 4 is lower priority than Track 3 per goals.md

---

#### 6th Priority: Idea #4 â€” "SAE-guided Inference-Time Safety Patching"
**Why this position:**
- SPIRIT already showed activation patching works; the extension (SAE-guided) is natural
- Safety track gets attention at conferences (NeurIPS, ICLR, ACL)
- But: requires adversarial training + security evaluation â†’ longer timeline
- Risk: responsible disclosure obligations may slow publication
- Should be attempted AFTER Track 2+3 papers establish Leo's base reputation

---

#### 7th Priority: Idea #6 â€” "Audio Causal Benchmark / Protocol" (Audio IOI)
**Why last:**
- Highest long-term impact IF done right (community tool everyone cites)
- But: most engineering-heavy (benchmark design, leaderboard, paper + code + stimuli)
- Least time-sensitive (community benchmarks don't expire as fast as research gaps)
- Best done AFTER Leo has experimental credibility from Papers A+B
- Consider merging this into AudioSAEBench (Paper B) rather than standalone paper

---

### Summary Ranking Table

| Rank | Idea | Feasibility | Impact | Competition | Timing |
|------|------|-------------|--------|-------------|--------|
| 1 | Paper A: Listen Layer | â­â­â­ MacBook | â­â­â­ | 0 causal competitors | NeurIPS May 2026 |
| 2 | Paper B: AudioSAEBench | â­â­ (reuses A) | â­â­â­ | Novel metrics | NeurIPS 2026 D&B |
| 3 | Audio T-SAE | â­ (needs GPU) | â­â­â­ | T-SAE authors risk | Interspeech 2027 |
| 4 | Neuron Grounding | â­ (LALM-scale) | â­â­ | Zhao 2601.03115 | NeurIPS 2026 |
| 5 | Causal AudioLens+LoRA | â­ (GPU+LoRA) | â­â­ | Low | EMNLP 2026 |
| 6 | SAE Safety Patching | â­â­ | â­â­ | SPIRIT | ICLR 2027 |
| 7 | Audio IOI Benchmark | â­ (max effort) | â­â­â­â­ | Low | Long-term |

---

### One-Line Research Thesis (updated synthesis)

> "Causal layer-wise patching reveals where and how audio representations are grounded in speech-language models, enabling principled evaluation of features (AudioSAEBench) and phoneme-aware temporal disentanglement (Audio T-SAE) â€” all building toward a mechanistically grounded picture of speech understanding in LLMs."

This thesis links Papers A+B+T-SAE as a coherent research program, not three disconnected papers.

---

### What This Cycle Produced
1. **7-idea priority ranking** â€” first time all ideas are ranked and justified together
2. **Corrected framing**: Audio T-SAE is #3 (not "just AudioSAEBench category"), Neuron Grounding is standalone idea #4
3. **Strategic consolidation**: Papers A+B share 60% infra â†’ do together; Audio T-SAE is 3rd standalone paper
4. **One-line thesis** â€” connects all 7 ideas into a coherent 12-month research program

## Next
- arXiv Feb 28 batch at ~14:00 Taipei â†’ cycle #74 = learn
- Leo review of priority ranking = this file + paper-a-pitch.md + paper-b-pitch.md
- Execution unblock still pending (real speech + venv + IIT approval)

## Tags: #reflect #synthesis #priority #portfolio #paper-a #paper-b #audio-T-SAE #research-program
