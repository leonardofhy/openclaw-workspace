# ðŸ§  Cycle #13 â€” 2026-02-26 21:00
## Action: learn
## Context: Post-AudioMatters CMT deadline. Toolchain verified (cycle #12). Recommended next = SPIRIT (Track 5 safety anchor paper). It's 9 PM â€” still high-energy for one focused learn cycle.

## Content: Deep Read â€” SPIRIT (arXiv:2505.13541v2)

**Full title:** "Patching Speech Language Models against Jailbreak Attacks"
**Authors:** Djanibekov, Mukhituly, Inui, Aldarmaki, Lukas â€” MBZUAI + Tohoku + RIKEN
**Venue:** EMNLP 2025
**Code:** https://github.com/mbzuai-nlp/spirit-breaking

---

### Problem
SLMs (Qwen2-Audio, LLaMa-Omni) are substantially more vulnerable to jailbreak attacks than text LLMs. Audio is a continuous, high-dimensional signal â†’ larger attack space than discrete text tokens. PGD-based adversarial audio perturbation achieves up to **100% Attack Success Rate** in some categories. Existing defense (SpeechGuard: add random noise) works but degrades utility.

### Method
**Attack:** Standard PGD adapted to audio domain. White-box access. Optimizer: cross-entropy loss w.r.t. target affirmative response. Constrained to Â±Îµ perturbation budget. Dataset: AdvBench (246 harmful English instructions) â†’ converted to speech via ElevenLabs + XTTSv2.

**Defense (the MI part):** Three activation-patching-based defenses:
1. **Activation Patching (cleanâ†’adv):** Run model on denoised/clean audio, capture activations at specific layers; inject those activations into the forward pass with adversarial audio. Intuition: adversarial perturbation operates in activation space; injecting clean activations "patches out" the attack signal.
2. **Bias Addition:** Add a learned bias term to specific layer activations to shift the model away from harmful output regions.
3. **Neuron Pruning:** Identify and suppress neurons that activate strongly on adversarial examples.

**Key ablation:** Which layer(s) to patch? They test all layers and find that patching at specific critical layers (middle-to-late layers of the encoder â†’ early LM layers) achieves best security/utility tradeoff.

### Results
- PGD attack achieves **100% ASR** on some harmful categories for Qwen2-Audio
- Activation patching defense reduces ASR to **~1%** (up to **99% robustness improvement**)
- Utility cost: negligible (WER/benchmark metrics barely change)
- Bias addition: also effective, slightly different tradeoff
- Neuron pruning: effective but higher utility cost
- **Best approach: activation patching at specific encoder output layers**

### Key Insight for Leo (Connection to Research Tracks)

**SPIRIT = proof-of-concept that activation patching IS a viable defense for audio safety.** But it's largely empirical â€” they don't explain *why* specific layers work, they just test by ablation.

**Gap Leo can exploit (Track 5 extension):**
1. SPIRIT doesn't use mechanistic interpretability to *understand* where the adversarial perturbation "lives" in activation space â€” they just find the best layer empirically
2. **SAE-guided defense**: Instead of arbitrary layer patching, use AudioSAE to identify which specific *features* encode adversarial signal â†’ surgically suppress those features = more targeted than SPIRIT's approach
3. SPIRIT tests Qwen2-Audio + LLaMa-Omni (both use Whisper encoder) â†’ Leo's Whisper hook infrastructure directly applicable
4. SPIRIT's "denoised reference activation" approach is essentially activation patching = pyvene can implement this

**Cross-paper synthesis:**
- AudioSAE showed 70% hallucination FPR reduction via suppressing 100 specific Whisper features
- SPIRIT shows activation patching reduces jailbreak success by 99%
- **Unification opportunity**: Use SAE features (interpretable) to guide SPIRIT-style patching â†’ SAE-guided inference-time safety patching. The features would be specific (sparse), interpretable, and causally validated via patching.

**Open Questions:**
1. Does SPIRIT's adversarial perturbation "live" predominantly in the acoustic layers (0-2) or semantic layers (3-5) of Whisper-base? If the Triple Convergence layer 3 transition is the attack boundary, that's a big finding.
2. Can AudioSAE-style feature steering replace SPIRIT's blind activation patching? (Feature steering = more interpretable, potentially more surgical)
3. SPIRIT uses Whisper encoder â†’ can the attack transfer if you patch at the Triple Convergence transition zone?

## Next: Two options for cycle #14
- **Option A (build):** Extend whisper_hook_demo.py to test logit-lens projection on Whisper layers 3-5 â€” verify "semantic" nature of post-transition representations. Directly relevant to both Triple Convergence and SPIRIT's patching insight.
- **Option B (learn):** Read AudioSAE code + SPIRIT code to understand how to connect SAE features to patching defenses. GitHub: https://github.com/audiosae/audiosae_demo + https://github.com/mbzuai-nlp/spirit-breaking

**Recommendation:** Option A (build) â€” 11 PM is late, keep it focused; the logit-lens extension is short (add ~50 lines to whisper_hook_demo.py) and directly empirical.

## Tags: #spirit #safety #activation-patching #jailbreak #slm #whisper #track5 #mech-interp
