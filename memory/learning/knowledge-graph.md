# ğŸ—ºï¸ Knowledge Graph

> æ¦‚å¿µã€è«–æ–‡ã€é€£çµã€‚Paper ideas è¦‹ goals.mdï¼ˆsingle source of truthï¼‰ã€‚
> Last updated: 2026-02-26 (based on deep research report)

## Mech Interp Ã— Speech/Audio â€” Field Map (2026)

### A) ASR / Whisper MI
- Ellena Reid (2023, LessWrong) â€” æ—©æœŸ Whisper MIï¼Œphoneme-like features, localized attention
- **Glazer et al. "Beyond Transcription" (2025, aiOla)** â€” ğŸŸ¢ DEEP READ â€” logit lens + probing + activation patching for Whisper-large-v3 + Qwen2-Audio [arXiv:2508.15882]
  - KEY METHODS: Encoder Lens (novel), saturation layer, white-noise reference patching
  - KEY FINDINGS: encoder encodes context (not just acoustics!), hallucination detectable from decoder residual stream (93.4% acc at layer 22), repetition = specific cross-attn heads
  - Speaker gender probing peaks layer 25 (94.6%), accent peaks layer 22 (97%), noise peaks layer 27 (90%)
  - DIRECT LINK to Track 3 (Listen vs Guess): saturation layer + patching sensitivity â†’ operationalize grounding coefficient
- Mozilla Builders (2024) â€” Whisper SAE (L1, TopK), phonetic/positional features
- Open tools: whisper-interp (GitHub), whisper_logit_lens (GitHub)

### B) Speech Encoder SAEs
- **AudioSAE (Aparin et al., 2026, EACL)** â€” SAE on Whisper/HuBERT all layers, feature steering æ¸›å°‘ false detection [arXiv:2602.05027]
- Parra et al. (2025, EMNLP) â€” interpretable sparse features for SSL speech models
- SAE on speaker embeddings (Titanet) â€” monosemantic factors [arXiv:2502.00127]

### C) Audio-Language Modelsï¼ˆæœ€æ¥è¿‘ Leoï¼‰
- **ğŸ”¥ AudioLens (æ™ºå‡±å“¥, 2025, NTU æå®æ¯… lab)** â€” logit-lens for LALMs, attribute tracking [arXiv:2506.05140]ï¼ˆLeo æœ€è¿‘çš„ labmateï¼ŒAudioMatters co-1st authorï¼‰
- Beyond Transcription ä¹Ÿæ¶µè“‹ Qwen2-Audio
- **SPIRIT (EMNLP 2025, MBZUAI)** â€” activation patching é˜²ç¦¦ audio jailbreak [arXiv:2505.13541]

### D) Generative Audio/Music MI
- SMITIN (2024), Facchiano (2025), TADA! (2026) â€” attention steering, SAE for music concepts
- TADA!: å°‘æ•¸ attention layers æ§åˆ¶ semantic concepts [arXiv:2602.11910]

### E) Brain-to-Speech
- Maghsoudi & Mishra (2026) â€” cross-mode patching, causal scrubbing [arXiv:2602.01247]

### F) Neural Audio Codecsï¼ˆæ–°è§’åº¦ï¼‰
- EnCodec â†’ discrete tokens â†’ è®“ audio MI è®Šæˆã€ŒLM-likeã€
- AudioLM, MusicGen/AudioGen éƒ½åŸºæ–¼ codec tokens
- MI æ„ç¾©ï¼štoken-level patching, SAE on residual stream ç›´æ¥å¯ç”¨
- ç›®å‰ MI ç ”ç©¶å¹¾ä¹ç©ºç™½

## æ ¸å¿ƒæ–¹æ³•å·¥å…·ç®±
â†’ è©³è¦‹ `skills/autodidact/references/toolbox.md`

## é—œéµç ”ç©¶è€…/åœ˜éšŠ
- **NTU æå®æ¯… lab** â€” AudioLens (æ™ºå‡±å“¥ï¼Leo ä¸»å ´)
- aiOla Research (Glazer) â€” ASR MI, hallucination causal analysis
- Huawei Noah's Ark (Aparin) â€” AudioSAE
- MBZUAI â€” SPIRIT (audio safety)
- Stanford (Atticus Geiger) â€” causal abstraction theory + pyvene
- Neel Nanda â€” activation patching best practices, TransformerLens
- Mozilla Builders â€” Whisper SAE tooling
- Ellena Reid â€” early Whisper MI (LessWrong)
- Yuan Gong (MIT) â€” AST/SSAST audio transformers
