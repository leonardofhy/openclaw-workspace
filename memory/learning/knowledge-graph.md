# ğŸ—ºï¸ AI PhD Knowledge Graph

> æŒçºŒæ›´æ–°çš„çŸ¥è­˜åœ°åœ–ï¼Œè¿½è¹¤æˆ‘å­¸åˆ°çš„æ¦‚å¿µã€è«–æ–‡ã€å’Œå®ƒå€‘ä¹‹é–“çš„é—œä¿‚

## æ ¸å¿ƒç ”ç©¶é ˜åŸŸ

### â­ Mechanistic Interpretability Ã— Speech/Multimodal (Leo ä¸»èˆˆè¶£)
- **ç¾æœ‰å·¥ä½œåƒ… 4 ç¯‡**ï¼ˆ2025-08 è‡³ 2026-02ï¼‰ï¼Œé ˜åŸŸå¹¾ä¹ç©ºç™½
- "Beyond Transcription" (2025-08) â€” ç¬¬ä¸€ç¯‡ systematic mech interp for ASR
- "Behind the Scenes" (2025-09) â€” Whisper + LoRA mech interp for SER
- "Brain-to-Speech Mech Interp" (2026-02) â€” neuroscience crossover
- "What Do Neurons Listen To" (2026-02) â€” audio SSL neuron dissection
- **Survey** (2025-02): è¦†è“‹ vision-languageï¼Œspeech å¹¾ä¹æœªæåŠ = GAP
- **Toolkit**: Vision æœ‰ Prismaï¼Œspeech/audio ç„¡å°æ‡‰ = GAP
- **é—œéµæ–¹æ³•**: activation patching, probing, SAE, logit lens

### â­ AI Safety Ã— Speech
- Jailbreak detection via activation disentanglement (2026-02)
- Adversarial activation patching for deception detection (2025-07)
- **Speech-specific safety ç ”ç©¶ = 0 ç¯‡** â†’ å·¨å¤§ gap

### Audio Representation Learning
- **UniWhisper** (2602.21772) â€” unified instruction format, continual multi-task, 20-task evaluation
  - ä¸Šæ¸¸: Whisper (OpenAI)
  - æ–¹æ³•: instruction-answer format â†’ next-token training
  - è©•ä¼°: MLP probe + kNN (lightweight)

### Audio Evaluation / Benchmarking
- **AudioMatters** (æˆ‘å€‘çš„!) â€” Interspeech 2026 æŠ•ç¨¿ä¸­
  - å¾…æ¯”è¼ƒ: UniWhisper çš„ 20-task coverage vs æˆ‘å€‘çš„ benchmark scope

### Emotional Audio Understanding
- **EmoOmni** (2602.21900) â€” E-CoT for multimodal emotional dialogue
  - æ¶æ§‹: Thinker-Talker with explicit emotional instruction

### Low-Resource ASR
- **TG-ASR** (2602.22039) â€” Taiwanese Hokkien, translation-guided
- **Bangla ASR** (2602.21741) â€” Whisper fine-tune + Demucs

## é—œéµæ¦‚å¿µç´¢å¼•
| æ¦‚å¿µ | é¦–æ¬¡è¦‹æ–¼ | ç­†è¨˜ |
|------|----------|------|
| Unified instruction format | UniWhisper | æŠŠç•°è³ª tasks çµ±ä¸€æˆ instructionâ†’answer |
| MLP probe evaluation | UniWhisper | Lightweight encoder å“è³ªè©•ä¼° |
| Emotional CoT (E-CoT) | EmoOmni | å¾æ„ŸçŸ¥åˆ°å›æ‡‰çš„æƒ…æ„Ÿæ¨ç†éˆ |
| PGCA mechanism | TG-ASR | å¤šèªè¨€ embedding èåˆ |

## å¾…è¿½è¹¤çš„ç ”ç©¶è€…/å¯¦é©—å®¤
- Yuxuan Chen (UniWhisper)
- Yi-Hsuan Yang lab @ å°ç£ (music/audio generation)
- Lei Xie group (EmoOmni, speech emotion)

## AudioMatters ç«¶å“åœ°åœ– (2026-02)

```
                    Scope
           Narrow â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Broad
           â”‚                      â”‚
Encoder    â”‚  UniWhisper           â”‚
Only       â”‚  (20 tasks,          â”‚
           â”‚   probe-based)       â”‚
           â”‚                      â”‚
           â”‚  SUPERB/HEAR         â”‚  â† AudioMatters ç›®æ¨™ä½ç½®
           â”‚  (older, pre-LLM)    â”‚  ï¼ˆè·¨å ´æ™¯ Ã— è·¨èƒ½åŠ› Ã— LLM-eraï¼‰
           â”‚                      â”‚
End-to-End â”‚  AudioRAG            â”‚
           â”‚  (retrieval only)    â”‚
           â”‚                      â”‚
           â”‚  EmoOmniEval         â”‚
           â”‚  (emotion only)      â”‚
           â”‚                      â”‚
           â”‚  PhoStream           â”‚
           â”‚  (streaming only)    â”‚
```

## ç´¯è¨ˆçµ±è¨ˆ
- è«–æ–‡å·²è®€: 2 (1 ç²¾è®€ + 1 ç«¶å“åˆ†æ covering 8 papers)
- è«–æ–‡å¾…è®€: 6
- å­¸ç¿’å¤©æ•¸: 1
