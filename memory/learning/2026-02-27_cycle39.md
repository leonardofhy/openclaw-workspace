# ðŸ§  Cycle #39 â€” 2026-02-27 13:01
## Action: learn
## Context: arXiv scan â€” Feb 26/27 batch; checking for new speech MI / audio interpretability papers. arXiv API rate-limited, so pivoted to directly reviewing papers from the most recent returned batch. Must-read list fully exhausted; looking for new signals in adjacent work.

## Content

### Papers Scanned (Feb 26 arXiv batch)

**MiSTER-E (Dutta et al., 2026, IISc Bangalore / Microsoft)** â€” 2602.23300 [cs.CL, eess.AS]
- "Mixture of Speech-Text Experts for Recognition of Emotions" â€” MoE with 3 branches: speech-only, text-only, cross-modal experts
- Gating mechanism dynamically weights expert outputs per utterance
- Trained with contrastive loss (speech-text alignment) + KL regularization (expert consistency)
- IEMOCAP: 70.9%, MELD: 69.5%, CMU-MOSI: 87.9% WF1
- **KEY LINK TO TRACK 3**: Their gating weights (g_speech vs g_text) are behaviorally measuring "Listen vs Guess" at the logit level â€” without causal grounding. Leo's approach (patching) tests the SAME question but causally. Gap: MiSTER-E's gating is post-hoc/learned, not mechanistic; doesn't tell you *where* in the network audio-vs-text info diverges.
- **Connection to grounding_coefficient**: gc = g_audio / (g_audio + g_text) using MiSTER-E's gating weights would be a simple proxy; causal patching (Leo's approach) is the mechanistic ground truth.
- Relevance: LOW-MEDIUM for reading depth, HIGH for framing â€” MiSTER-E is a good motivation paper ("behavior shows modality dominance varies â†’ mechanism unknown â†’ we localize it causally")

**SemanticVocoder (Xie et al., 2026)** â€” 2602.23333 [cs.SD]
- Audio generation model using semantic encoder latents instead of VAE acoustic latents
- Relevance: LOW â€” audio generation, not interpretability

### arXiv Status (13:01 Taipei time)
- Feb 27 submissions not yet appearing (typically posted ~14:00-16:00 Taipei)
- Rate-limited on API â€” will retry next cycle at ~14:00

## Next: Wait for Feb 27 arXiv batch (~14:00 Taipei); meanwhile queue is depleted. Leo's action items remain: (1) approve IIT experiment, (2) real speech test, (3) venv+nnsight setup.

## Tags: #arxiv-scan #track3 #listen-vs-guess #MoE #emotion-recognition #grounding-coefficient
