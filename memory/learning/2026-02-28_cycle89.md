# ğŸ§  Cycle #89 â€” 2026-02-28 20:01
## Action: learn (skill-up â€” ARENA [1.3.1] Linear Probes curriculum study)
## Context: Saturday evening. arXiv weekend = no batch until Monday. Meta-board saturated (declared last meta cycle at #88). Cycle #88 explicitly recommended "ARENA before pyvene/NNsight code". High-value action available: read the ARENA [1.3.1] Linear Probes exercises (confirmed live on `alignment-science` branch) to internalize methodology directly needed for Paper A's gc(k) layer sweep.

## Content

### ARENA [1.3.1] Linear Probes â€” Curriculum Study

**Source:** `callummcdougall/ARENA_3.0` branch `alignment-science`, file `11_[1.3.1]_Linear_Probes.md`
**Status:** FULLY READ (core sections 1-3 + methodology)

---

### Key Methodological Learnings

#### 1. Activation Extraction Pattern (critical for Paper A)
```python
# Standard pattern: extract last-token hidden state at layer L
outputs = model(**inputs, output_hidden_states=True)
last_token_idx = inputs["attention_mask"].sum(dim=1) - 1
hidden = outputs.hidden_states[L + 1]  # hidden_states[0] = embedding, [L+1] = layer L output
acts = hidden[batch_indices, last_token_idx]  # [batch, d_model]
```
**Audio adaptation:** For Whisper encoder, we need frame-level activations, not last-token. The equivalent is: extract hidden state at the "commitment frame" = saturation layer frame. For audio LLMs (DeSTA2, Qwen2-Audio), the audio token positions replace the last-token logic.

#### 2. Difference-of-Means (MM) vs Logistic Regression (LR) Probes
- **MMProbe:** direction = `mean(true_acts) - mean(false_acts)` â€” simple, interpretable, **more causally implicated**
- **LRProbe:** trained via sklearn `LogisticRegression(C=0.1, fit_intercept=False)` with `StandardScaler` normalization
- **Crucial finding:** MMProbe finds a MORE CAUSALLY IMPLICATED direction than LRProbe, despite LRProbe having higher classification accuracy
- **Why:** LRProbe maximizes decision boundary accuracy; MMProbe finds the direction of maximum variance between classes = the direction the model actually USES in computation
- **Direct application to Paper A:** Use MMProbe (difference-of-means) for computing gc(k), not LR. The "audio mean - no-audio mean" direction = the grounding direction per layer.

#### 3. Layer Sweep Protocol (exact template for gc(k) curve in Paper A)
```
For each layer L:
  1. Extract activations at layer L for audio+text and text-only conditions
  2. Compute MMProbe direction (mean(audio) - mean(no-audio))
  3. Classify: sign of dot product with direction
  4. Test accuracy = gc(k) at layer k
```
Expected finding (from Geometry of Truth): early-to-mid layers peak; very early and very late layers are lower.
**Audio prediction:** Peak grounding layer should match Triple Convergence Hypothesis (layer 6-7 in Whisper, or mid-depth LLM layers for audio LLMs).

#### 4. Cross-Dataset Generalization Matrix (Paper A validation tool)
- Train probe on condition A, test on condition B â†’ generalization = universal direction
- For Paper A: train gc(k) on Speech Commands clean stimuli, test on ALME conflict stimuli
- If the "listen direction" generalizes = the model uses ONE audio pathway, not task-specific shortcuts
- High off-diagonal = strong evidence for "Listen Layer" universality

#### 5. Causal Intervention Protocol (Section 3 â€” most critical for Paper A)
```
1. Identify probe direction d (at INTERVENE_LAYER, not PROBE_LAYER â€” paper uses layer 8 vs 14!)
2. Patch: h_new = h - 2 * (h @ d / ||d||Â²) * d  (reflection through hyperplane)
3. Measure: does the model's prediction flip?
4. IIT accuracy = fraction of correct flips
```
**KEY INSIGHT:** MM probes are better for causal intervention than LR probes, even though LR has higher classification accuracy. The causally implicated direction â‰  the maximally discriminative direction.

**Direct Paper A application:**
- PROBE_LAYER â‰  INTERVENE_LAYER â€” need to sweep both to find the right pair
- gc(k) = IIT accuracy at layer k using DAS (learned linear subspace) â€” theoretically grounded
- The IIT experiment tests whether patching the "audio direction" at layer k causes correct behavior change

#### 6. Attention Probes for Sequence-Level Evidence (Section 5 â€” new tool!)
- Single learned query that computes weighted sum over ALL token positions before classification
- `attention_probe = softmax(Q Â· K) weighted sum over positions` â†’ fed to linear classifier
- Outperforms last-token and mean-pool for detecting "high-stakes" interactions
- **Audio application:** For audio tokens that span many positions, attention probe > last-token probe
  - Whisper audio tokens = 1500 patches per second; relevant phoneme = only 3-5 frames
  - Attention probe would LEARN which frames are diagnostic â†’ better than last-token extraction

---

### Synthesis: ARENA [1.3.1] â†’ Paper A Method Section

**Upgraded Paper A methodology (post-ARENA study):**

1. **Activation extraction:** Use ARENA's `extract_activations` pattern, adapted for Whisper encoder frames + audio LLM audio token positions
2. **Probe type:** Use MMProbe (difference-of-means) for gc(k), NOT logistic regression â€” more causally implicated
3. **Layer sweep:** Follow layer_sweep_accuracy pattern for gc(k) curve â€” sweep all layers, identify peak = "Listen Layer"
4. **Cross-generalization:** Validate: train on Speech Commands stimuli, test on ALME conflict stimuli
5. **Causal validation:** Patch with MM direction at layer k, measure IIT accuracy â€” proves causal implication
6. **Attention probe baseline:** Compare attention probes vs last-token for audio token positions

**New insight for Paper A Section 3:**
> *"We find that the difference-in-means directions are more causally implicated in the model's computation of truth values than the logistic regression directions"* (Geometry of Truth, 2024)
>
> â†’ Analogously, the difference-in-means direction between "audio-consistent response" and "text-consistent response" is predicted to be the most causally implicated grounding direction in speech LLMs.

---

### Gap Reinforced by ARENA Study

**Gap #18 (phonological geometry through connector) now has cleaner experiment design:**
- Extract MMProbe direction for voicing from S3M encoder (phoneme-aware difference-of-means)
- Test whether this direction survives through connector into LLM layer 0 residual stream
- Causal test: patch voicing direction at LLM layer 0 â†’ does phonological prediction flip?
- This is exactly the ARENA Section 3 causal intervention protocol, applied to phonology

**Gap #12 (temporal SAE) + Audio T-SAE:**
- ARENA attention probe methodology (Section 5) = non-parametric version of T-SAE temporal coherence
- Attention probe weights over audio frames â‰ˆ temporal importance weights
- Could be a lightweight BASELINE for TCS(F) metric in Paper B before training full T-SAE

---

### New Technical Reference: `circuit-tracer` (from ARENA [1.4.2] SAE Circuits)
Confirmed in `alignment-science` branch: exercise `22_[1.4.2]_SAE_Circuits.md` builds attribution graphs using `circuit-tracer` library. This is directly applicable for Track 1 (Audio IOI / circuit graph). Confirmed it's a separate module from Linear Probes; Leo should study this after Linear Probes.

---

## Connection to Goals
- Paper A: ARENA provided the exact probe methodology (MMProbe > LRProbe for causal interventions, PROBE_LAYER â‰  INTERVENE_LAYER distinction, layer sweep protocol)
- Paper B: Attention probe from Section 5 = new AudioSAEBench methodology tool
- Skill gap: "TransformerLens + pyveneå®ä½œ" and "Causal abstractionç†è®ºåŸºç¡€" both addressed â€” MMProbe/LRProbe = concrete implementation template
- Recommended path: ARENA [1.3.1] Linear Probes â†’ ARENA [1.4.2] SAE Circuits â†’ then build IIT experiment with pyvene/NNsight

## Next
- **Next cycle (#90):** arXiv weekend = no new papers. Consider reading ARENA [1.4.2] SAE Circuits (attribution graphs, circuit-tracer) â€” directly serves Track 1 Audio IOI gap. OR: read "Geometry of Truth" paper (arXiv:2310.06824) for deeper theoretical grounding (cited by ARENA as prerequisite).
- **Monday (~14:00 Taipei):** arXiv Feb 28/Mar 1 batch scan = back to `learn` mode with fresh papers
- **Leo action queue:** unchanged â€” IIT experiment approval + real speech test + venv setup still needed

## Tags: #ARENA #linear-probes #skill-up #MMProbe #causal-intervention #paper-a #gc-k #layer-sweep #audio-adaptation
