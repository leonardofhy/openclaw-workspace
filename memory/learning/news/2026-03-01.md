# ğŸ“° News Digest â€” 2026-03-01

> 3 relevant items (threshold: relevance â‰¥ 7)

## 1. [Why Did My Model Do That? Model Incrimination for Diagnosing LLM Misbehavior](https://www.alignmentforum.org/posts/Bv4CLkNzuG6XYTjEe/why-did-my-model-do-that-model-incrimination-for-diagnosing)
**ğŸ”µ AF** | Relevance: 8/10
**Why**: ç›´æ¥è¨è«–æ¨¡å‹è¡Œç‚ºè¨ºæ–·ï¼Œèˆ‡æ©Ÿåˆ¶å¯è§£é‡‹æ€§/å®‰å…¨æ€§èˆ‡éŒ¯èª¤æ©Ÿç†åˆ†æé«˜åº¦ç›¸é—œã€‚

## 2. [How will we do SFT on models with opaque reasoning?](https://www.alignmentforum.org/posts/GJTzhQgaRWLFJkPbt/how-will-we-do-sft-on-models-with-opaque-reasoning)
**ğŸ”µ AF** | Relevance: 8/10
**Why**: èšç„¦ä¸å¯è§£é‡‹æ¨ç†ä¸­çš„å°é½Šèˆ‡å¾®èª¿æµç¨‹ï¼Œå°æ©Ÿåˆ¶è§£é‡‹èˆ‡å®‰å…¨ç ”ç©¶å¯ç›´æ¥å•Ÿç™¼ã€‚

## 3. [The Science of Detecting LLM-Generated Text](https://dl.acm.org/doi/10.1145/3624725)
**ğŸŸ  HN** | Relevance: 7/10
**Why**: é—œè¯æ–¼æª¢æ¸¬èˆ‡å®‰å…¨é‚Šç•Œï¼Œèˆ‡ AI safety ç ”ç©¶ä¸­çš„å¯å¯©æ ¸æ€§èˆ‡å°æŠ—é¢¨éšªç›£æ§ç›¸é—œã€‚

