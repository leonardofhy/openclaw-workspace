# ðŸ§  Cycle #101 â€” 2026-03-01 02:01
## Action: learn (foundational paper â€” Weekend Protocol option b)
## Context: Cycle #100 designated DAS foundational paper (arXiv:2303.02536) as next action. Weekend gap (arXiv batch ~38h away, Monday ~14:00 Taipei). Execution-blocked: real speech + venv + Leo approval pending. Running Weekend Protocol option (b) = foundational paper read.

---

## Paper: DAS â€” "Finding Alignments Between Interpretable Causal Variables and Distributed Neural Representations"
**Authors:** Atticus Geiger, Zhengxuan Wu, Christopher Potts, Thomas Icard, Noah D. Goodman (Stanford Pr(Ai)Â² Group)
**arXiv:** 2303.02536 (cs.AI) â€” last updated Feb 2024 (v4)

### Problem DAS Solves
Prior causal abstraction methods (IIA â€” Interchange Intervention Accuracy) have two critical limitations:
1. **Brute-force search**: computationally intractable for large models
2. **Localist assumption**: assumes high-level variables align with *disjoint sets of neurons* â€” wrong assumption (neurons are polysemantic, play multiple roles)

### DAS Method â€” Core Mechanics

**High-level causal model** = symbolic algorithm with intermediate variables (e.g., "compute w=x, compute y=z, then output (w=x)=(y=z)")

**Low-level model** = neural network

**Goal**: Find a mapping (alignment) from high-level variables to *subspaces* of neural representations

**Distributed interchange intervention (key operation):**
1. Take neural representation at a group of neurons
2. **Rotate** the representation using a learned change-of-basis matrix R
3. Fix the **targeted dimensions** (d_low dimensions) of the rotated representation to values from a source input
4. Rotate back to standard basis
5. Continue forward pass
â†’ This is a "soft" intervention that operates on a learned *direction* in representation space, not on individual neurons

**Learning procedure:**
- Use **gradient descent** to learn the rotation matrix R (instead of brute-force search)
- Optimize **IIT objective**: minimize mismatch between high-level intervention outcome and low-level intervention outcome
- When IIT loss â†’ 0: the distributed representation *is* a faithful causal abstraction of the high-level model

**IIA (Interchange Intervention Accuracy)** = fraction of interventions where high-level and low-level models produce the same output. IIA = 100% â†’ the models are provably causally equivalent at that level.

### Key Results
- **Hierarchical equality task**: DAS finds 100% IIA distributed alignment; localist brute-force finds only partial alignment â†’ DAS reveals structure that neuron-level analysis misses
- **NLI task**: DAS finds 100% IIA; reveals that "lexical entailment" is actually encoded as *two separate word identity representations* (not a semantic entailment relation) â†’ DAS provides insight that surprises researchers

### Why This Matters for Paper A (Listen Layer)

**gc(k) formulation upgrade (confirmed):**
> gc(k) = IIA at layer k using DAS (RotatedSpaceIntervention in pyvene)

This is STRICTLY BETTER than vanilla activation patching because:
1. Vanilla patching = localist (forces alignment to individual neurons)
2. DAS = finds the *optimal subspace* for the "audio grounding variable" even if it's distributed across neurons
3. The "audio grounding" concept likely IS distributed (not localized to individual neurons), so DAS > vanilla for Paper A

**Concrete link to pyvene:**
- pyvene implements `RotatedSpaceIntervention` = DAS's distributed interchange intervention
- `pyvene.RotatedSpaceIntervention(d_low=k)` = intercept layer k's residual stream â†’ rotate â†’ fix d_low dimensions to source-input values â†’ rotate back
- Training this rotation = finding where "is_listening_to_audio" is encoded in the model's distributed representation

**Audio grounding causal model (for Paper A):**
```
High-level: X_audio â†’ [GROUNDING_VARIABLE] â†’ {listen, guess}
Low-level: audio_tokens â†’ layer k residual stream (DAS subspace) â†’ LM output
IIA(k) = DAS accuracy at layer k = gc(k)
```
Layer with peak IIA(k) = "Listen Layer" â€” the layer where audio is causally consulted as a structured variable.

### Key Insight: DAS Finds What Vanilla Patching Misses

In the NLI task example: localist patching would assign "entailment" to one neuron group. DAS reveals it's actually a *joint data structure of two word representations* â€” the model doesn't encode "entailment" as a primitive at all. In Leo's case: vanilla patching might suggest no single "listen" layer because the grounding information is *distributed* across neurons. DAS would still find it as a linear subspace across those neurons. This is why DAS = better methodology for Paper A than what FCCT competitor (Li et al. 2511.05923) uses (they use vanilla causal tracing like Meng/ROME).

### Connection to other methods:
- IIA = graded version of exact causal abstraction â†’ approximate causal abstraction theorem (Geiger et al. 2023)
- DAS is implemented in **pyvene** (same library Wu et al. built pyvene for) â†’ `pip install pyvene` = everything needed
- DAS generalizes: probe â†’ localist patching â†’ DAS â†’ all on the same abstraction ladder, DAS is the top rung

### Open Questions for Leo's Research
1. What is the dimensionality d_low for the "audio grounding subspace"? (hypothesis: d_low=1 if clean binary listen/guess, d_low=10-20 if grading by confidence)
2. Does DAS find the same layer as vanilla patching, or does it reveal a different (deeper?) layer? The mismatch would itself be a finding.
3. Can the learned rotation matrix R be used to define a new SAE feature "Audio Grounding Direction" for Paper B AudioSAEBench?
4. Does DAS generalize across speech LLMs (Qwen2-Audio vs DeSTA2 vs Audio Flamingo)? Cross-model IIA comparison = a new table for Paper A.

## Next: Option (c) â€” Pre-flight design doc for Priority 0 experiment (phonological geometry, Gap #18)
Remaining weekend options: (b) âœ… DAS done; (c) not yet done â†’ next cycle should write exact stimuli list + pyvene skeleton for Gap #18 experiment

## Tags: #DAS #IIT #pyvene #causal-abstraction #distributed-representations #paper-a #gc-k #foundation
