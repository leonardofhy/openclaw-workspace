# ðŸ§  Cycle #87 â€” 2026-02-28 19:01
## Action: learn (tool recon â€” SAELens audio gap survey)
## Context: Saturday 7 PM. arXiv weekend = no batch. Meta-board saturated (cycle #63 cap, 6/6 answered). Last productive cycle was #86 (ARENA curriculum mapping) which surfaced SAELens as a key pre-trained SAE registry. High-value 5-min action: verify whether ANY audio/speech pre-trained SAEs exist in the SAELens ecosystem â€” this directly determines if Leo needs to train from scratch or can load existing weights.

## Content

### SAELens v6 â€” Key Facts

**Library:** `decoderesearch/SAELens` (formerly `jbloomAus/SAELens`)
- **Version:** SAELens 6.0.0 (live, recent major release)
- **Install:** `pip install sae-lens`
- **API:** `SAE.from_pretrained(release, sae_id, device)` â€” loads from HuggingFace
- **Compatibility:** Works with NNsight, HuggingFace Transformers, or any PyTorch model â€” NOT limited to TransformerLens
- **Key method:** `sae.encode()`, `sae.decode()`, `sae.forward()` accept standard PyTorch tensors

### Pre-trained SAEs Available on HuggingFace (`library=saelens`)

Complete model list (25 entries, manually scanned):
- **Google Gemma-scope**: Gemma 2 (270M, 1B, 2B, 12B, 27B) â€” PT + IT variants, residual/attention/MLP/transcoders
- **GPT-2 Small**: `jbloom/GPT2-Small-SAEs-Reformatted`
- **LLaMA 3-8B**: `Juliushanhanhan/llama-3-8b-it-res`
- **Tiny models**: tinystories, tetrahedron, ARENA demos
- **Other**: upload demos, polynomial SAE, random-seed variants

### ðŸ”´ Critical Finding: ZERO Audio/Speech SAEs in SAELens Ecosystem

**Searched for:**
- Whisper SAEs â†’ 0
- HuBERT SAEs â†’ 0
- WavLM SAEs â†’ 0
- Any audio/speech model SAEs â†’ 0

**Conclusion:** The entire SAELens pre-trained ecosystem is **text-LLM-only**. No audio SAE has been uploaded to HuggingFace with the `saelens` tag.

This means for Leo's research:
- **AudioSAEBench** (Paper B) = must train audio SAEs from scratch â†’ this is the contribution, not a limitation
- The 5 audio SAE papers (AudioSAE, Mariotte, AR&D, Plantinga-PD, Paek et al.) all use custom training code, NOT SAELens â€” nobody has standardized audio SAE training
- **Gap #19 (NEW)**: No standardized SAE training/evaluation pipeline for audio models. SAELens works for LLMs; audio models lack the equivalent. **AudioSAEBench could also include an open-source SAE training toolkit** as a community contribution.

### SAELens Ã— NNsight Integration (Confirmed)

SAELens v6 explicitly supports NNsight:
```python
# Pattern: extract activations with NNsight â†’ pass to SAELens SAE
with model.trace(input):
    acts = model.encoder.layers[6].output.save()
sae = SAE.load_from_disk("/path/to/custom_audio_sae")
features = sae.encode(acts.value)
```
This is the correct interface for Leo's workflow: train a custom audio SAE (using SAELens training code), save to disk, then use NNsight hooks + SAELens encode for feature analysis.

### SAELens Training Code for Audio Models

Even though no pre-trained audio SAEs exist, Leo can use SAELens' **training code** as the backbone:
- SAELens training = framework-agnostic; just needs activations tensor
- Workflow: NNsight hook â†’ extract Whisper/HuBERT activations â†’ feed to SAELens trainer
- This standardizes Leo's SAE training and makes Paper B's results reproducible with `pip install sae-lens`
- **Strategic benefit**: if AudioSAEBench uses SAELens format, future researchers can load Leo's trained SAEs directly â†’ community adoption

### Transcoders Available

`google/gemma-scope-2b-pt-transcoders` (May 2025) â€” transcoders are SAE variants that reconstruct MLP computation, needed for ARENA [1.4.2] SAE Circuits exercise. Confirms ARENA [1.4.2] is MacBook-feasible with Gemma 2-2B.

## Gap Update
- **Gap #19 (NEW)**: Zero standardized audio SAE training pipeline (SAELens = text-LLM-only). AudioSAEBench can fill this gap by providing both evaluation protocol AND a `pip install`-able training backbone.

## Next
- **Monday ~14:00 Taipei**: arXiv batch scan (first after weekend)
- **Leo action queue update**: Add "use SAELens training code as audio SAE backbone" to Paper B design
- **ARENA [1.3.1] Linear Probes**: first study session (text-LLM, build methodology before running audio IIT experiment)

## Tags: #learn #SAELens #tool-recon #audio-SAE #gap19 #paper-b
