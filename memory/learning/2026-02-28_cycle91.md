# ðŸ§  Cycle #91 â€” 2026-02-28 21:01
## Action: learn (pre-digest â€” Anthropic "Biology of a Large Language Model" + CLT/Attribution Graph Case Studies)
## Context: Q9 rule: execution-blocked + meta-board saturated (7/7) + arXiv Saturday sparse â†’ read Anthropic primary sources and write pre-digest for Leo. Cycle #90 pre-digested the Methods paper; this cycle covers the companion Case Studies paper (biology.html) which shows how attribution graphs are applied in practice. Direct relevance to Paper A (Listen Layer) and Paper B (AudioSAEBench).

---

## Content: "On the Biology of a Large Language Model" â€” Pre-Digest for Leo

**Source:** Anthropic, 2025 â€” Companion paper to Circuit Tracing
URL: https://transformer-circuits.pub/2025/attribution-graphs/biology.html

---

### What this paper IS (vs the methods paper cycle #90 pre-digested)

| Methods paper (cycle #90) | Biology paper (this cycle) |
|--------------------------|---------------------------|
| HOW attribution graphs are built (CLT, replacement model, pruning) | WHAT attribution graphs reveal (case studies on Claude 3.5 Haiku) |
| Pipeline + theory | Empirical discoveries |
| Prerequisite for ARENA [1.4.2] | Evidence that the method works on frontier models |

Both papers are needed to fully understand the field; the biology paper shows the **research payoff**.

---

### Architecture Recap (from methods pre-digest + expanded here)

- **CLT (Cross-Layer Transcoder)**: replaces MLP neurons with ~30M sparse features across all layers
- **Local Replacement Model**: uses CLT features + original attention patterns + error nodes (gap filler)
- **Attribution graph**: directed graph per prompt; nodes = active features; edges = causal contributions to output
- **Intervention experiments**: verify hypotheses by steering features â†’ check downstream changes

---

### Key Case Studies and What They Mean for Leo's Research

#### 1. Multi-step Reasoning ("Dallas â†’ Texas â†’ Austin")
- Model represents "Texas" as an **internal intermediate step** â€” never written to output
- Attribution graph makes this visible: `[Dallas entity feature] â†’ [Texas state feature] â†’ [Austin answer feature]`
- **Audio analog**: "What emotion is in this audio?" might follow a chain:
  - `[phoneme features at layer k] â†’ [prosody/emotion feature in LLM layer m] â†’ [emotion label]`
  - Attribution graph would reveal this chain explicitly
  - This is what Paper A's "Listen Layer" experiment would uncover â€” but with causal patching (NNsight), not CLT

#### 2. Refusal Mechanisms
- A **general-purpose "harmful requests" feature** emerges from finetuning
- Specific harmful topic features (learned in pretraining) are aggregated into this general feature during RLHF
- **Audio safety implication (Track 5)**: Audio jailbreak defense (SPIRIT) may work because adversarial audio activates the same harmful-requests feature pathway â€” just through the audio encoder instead of text. The CLT attribution graph approach could verify this without black-box probing.
- **New synthesis**: Gap #17 (Audio T-SAE) + Track 5 (SPIRIT) could be connected: T-SAE temporal features at phoneme timescale may include "adversarial trigger" features that â†’ CLT â†’ harmful-requests feature. SAE-guided defense = principled.

#### 3. Chain-of-Thought Faithfulness
- The paper can distinguish: (a) model actually follows CoT steps, (b) model makes up reasoning, (c) model "works backwards" from human hint
- **Hallucination detection connection**: Beyond Transcription (cycle #6) found hallucination detectable from decoder residual stream (93.4% acc). CLT attribution graphs would reveal which features cause the hallucination â€” going deeper than prediction.
- **AudioSAEBench metric extension**: a "causal faithfulness" evaluation â€” does the SAE feature that activates during hallucination *causally* precede the hallucination output? (i.e., steer that feature â†’ hallucination rate changes). This is Category 4 (Causal Controllability) of AudioSAEBench.

#### 4. Multilingual Circuits
- Model uses **language-specific AND language-independent circuits**
- Language-independent circuits more prominent in larger (more capable) models
- **Cross-lingual audio extension**: Choi et al. (cycle #81) showed phonological vectors are cross-lingual in S3M space. If CLT attribution graphs show audio feature â†’ language-independent LM circuit (not language-specific), this confirms the phonological geometry survived the connector. Directly tests Gap #18.

#### 5. Limitations (Critical for Leo)

> "Attribution graphs provide satisfying insight for about **~25% of prompts** we've tried."

This is honest and important. CLT/attribution graphs are NOT a silver bullet:
- Fail when mechanisms are distributed and dense (vs sparse)
- Fail for complex long-range dependencies
- Error nodes (unexplained gaps) can be large
- Attention patterns are frozen â€” cross-attention missed

**Implication for Paper A**: NNsight activation patching (layer-level causal sweep) is MORE robust than CLT attribution graphs for the "Listen Layer" identification problem, because:
1. Layer-level patching gives you ONE number per layer (gc(k)) â€” works even if mechanism is distributed
2. Attribution graphs require sparsely-firing features â€” audio representations may be dense (SAE papers show audio needs MORE features than text)
3. Patching doesn't need a replacement model â€” direct intervention on original model

**Recommendation**: Use patching for Paper A (main contribution); flag CLT/attribution graphs as future work ("our approach localizes the layer; CLT would reveal the specific features in that layer").

---

### Method Hierarchy (Cumulative View After Pre-Digests #90+#91)

```
Level 1 (DONE âœ…): Probing + logit-lens (observational â€” WHERE is info represented?)
Level 2 (Paper A): Activation patching with NNsight (causal â€” WHAT layer CAUSES the output?)
         â†’ gc(k) metric = DAS-based grounding coefficient per layer
         â†’ MMProbe direction + sweep = same loop (ARENA [1.3.1] template)
Level 3 (follow-up): CLT attribution graphs (feature-level causal â€” WHICH feature CAUSES which other feature?)
         â†’ circuit-tracer library
         â†’ Limitation: attention frozen, needs sparse features, ~25% success rate
         â†’ Better for LM backbone analysis; NNsight better for encoder-encoder-decoder cross-modal
```

**Leo's research covers Levels 1+2 in Paper A; Level 3 = future work or co-authorship with Anthropic-aligned lab**

---

### Concrete Tool Note: Interactive Attribution Graph Explorer

The biology paper ships with an **interactive interface** for exploring attribution graphs on their case studies.

URL: https://transformer-circuits.pub/2025/attribution-graphs/biology.html#dives-tracing (interactive embeds in page)

**For Leo**: use this interactively (browser, not code) to:
1. Understand how the pruned graph looks visually (before implementing your own)
2. Test intuitions about what makes a good vs bad graph
3. Use as a figure reference for Paper A's "expected output" section

---

### What's New That Wasn't in the Methods Pre-Digest (cycle #90)

1. **~25% success rate** â€” realistic expectation for CLT attribution graphs (not in methods paper)
2. **Multilingual circuits â†’ Gap #18 test** â€” language-independent circuits at CLT level = connector geometry preservation test
3. **Refusal mechanism = finetuning aggregation** â€” informs Track 5 audio safety interpretation
4. **CoT faithfulness** â†’ AudioSAEBench Category 4 (Causal Controllability) extension
5. **Case study confidence**: CLT attribution graphs work on frontier models (Claude 3.5 Haiku) â€” validates the approach for smaller audio models where features may be even sparser

---

### Meta-Awareness Note

This pre-digest completes the pair:
- Cycle #90: Methods paper â†’ how to BUILD attribution graphs
- Cycle #91: Biology paper â†’ how to USE attribution graphs, success/failure cases, realistic expectations

Together these give Leo ~50% headstart for ARENA [1.4.2] SAE Circuits exercises.

**Next pre-digest candidate** (if still blocked tomorrow):
- ARENA [1.3.1] exercises themselves (if Streamlit is accessible via browser â€” Leo can run these)
- OR: `circuit-tracer` GitHub README for concrete installation + usage example

---

## Next:
- arXiv Monday batch (~14:00 Taipei Mon March 2) â€” next major external novelty
- Leo's Day-1 unblock session plan: see `memory/learning/2026-02-28_cycle88.md`
- Paper pitches ready: `paper-a-pitch.md` + `paper-b-pitch.md`

## Tags: #circuit-tracing #attribution-graphs #biology #clt #pre-digest #paper-a #paper-b #arena #meta-awareness #hallucination #multilingual #safety
