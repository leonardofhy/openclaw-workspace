# ğŸ¯ Conference Publication Pipeline

> ç›®æ¨™ï¼šä»¥ AI PhD student çš„æ¨™æº–ï¼ŒæŒçºŒç”¢å‡º top conference è«–æ–‡

## ç•¶å‰æŠ•ç¨¿é€²åº¦

### ğŸ”´ Active â€” Interspeech 2026
- **è«–æ–‡**: AudioMatters (1st author!)
- **CMT å¡ä½æˆªæ­¢**: 2026-02-26 19:00 âš ï¸ ä»Šå¤©ï¼
- **æœ€çµ‚ PDF æˆªæ­¢**: 2026-03-05
- **ç‹€æ…‹**: å¯¦é©—æ•¸æ“šå……è¶³ï¼Œè«–æ–‡æ¡†æ¶è¨è«–ä¸­

## ä¸‹ä¸€æ­¥ç›®æ¨™ Conferenceï¼ˆæŒ‰ deadline æ’åºï¼‰

### Tier 1 Speech/Audio
| Conference | é ä¼° Deadline | å‚™è¨» |
|-----------|--------------|------|
| Interspeech 2026 | âœ… é€²è¡Œä¸­ | AudioMatters |
| ASRU 2026 | ~2026-06 | IEEE, speech recognition |
| SLT 2026 | ~2026-09 | IEEE, spoken language |
| ICASSP 2027 | ~2026-10 | IEEE, signal processing é ‚æœƒ |

### Tier 1 ML/NLP
| Conference | é ä¼° Deadline | å‚™è¨» |
|-----------|--------------|------|
| NeurIPS 2026 | ~2026-05 | ML é ‚æœƒ |
| EMNLP 2026 | ~2026-06 | NLP é ‚æœƒï¼ŒARR rolling |
| ACL 2027 | ~2026-10 | NLP æœ€é ‚ï¼ŒARR rolling |
| ICLR 2027 | ~2026-09 | ML é ‚æœƒ |

## æˆ‘ï¼ˆAI agentï¼‰èƒ½åšçš„å…·é«”äº‹æƒ…

### ğŸ“Š Phase 1: Research Gap Discoveryï¼ˆç¾åœ¨é–‹å§‹ï¼‰
- [x] æ¯æ—¥ arXiv Radar â€” æƒææ–°è«–æ–‡ã€è¿½è¹¤è¶¨å‹¢
- [x] æ¯ 30 min ç²¾è®€ â€” ç´¯ç© domain knowledge
- [x] Knowledge Graph â€” ä¸²è¯æ¦‚å¿µé—œä¿‚
- [ ] **Gap Analysis** â€” æ¯é€±å¾è®€éçš„è«–æ–‡ä¸­æç…‰ 3 å€‹ open problems
- [ ] **Related Work è‡ªå‹•æ•´ç†** â€” çµ¦å®š topicï¼Œè‡ªå‹•æœé›†+åˆ†é¡ related work

### ğŸ”¬ Phase 2: Experiment Supportï¼ˆAudioMatters æŠ•ç¨¿å¾Œï¼‰
- [ ] å¹«å¯« experiment scriptsï¼ˆæ•¸æ“šè™•ç†ã€evaluation pipelineï¼‰
- [ ] è‡ªå‹•è·‘ baseline æ¯”è¼ƒ
- [ ] çµæœå¯è¦–åŒ–ï¼ˆtables, plotsï¼‰
- [ ] Ablation study è¨­è¨ˆå»ºè­°

### âœï¸ Phase 3: Paper Writing
- [ ] Related work section è‰ç¨¿
- [ ] è«–æ–‡æ¨¡æ¿æº–å‚™ï¼ˆLaTeX, conference formatï¼‰
- [ ] Rebuttal è¼”åŠ©ï¼ˆreviewer comment åˆ†æ + å›è¦†è‰ç¨¿ï¼‰

### ğŸ“… Phase 4: Ongoing
- [ ] Conference deadline trackerï¼ˆè‡ªå‹•æé†’ 30/14/7 å¤©å‰ï¼‰
- [ ] æ¯é€± research summaryï¼ˆæœ¬é€±è®€äº†ä»€éº¼ã€æœ‰ä»€éº¼ insightï¼‰
- [ ] è¿½è¹¤ç«¶çˆ­è€…çš„æ–°å·¥ä½œ

## ğŸ”¬ Research Direction: Mech Interp Ã— Speech Multimodal LM

### Why This Is Gold
- arXiv ä¸Š "mechanistic interpretability" + "speech" åªæœ‰ **4 ç¯‡è«–æ–‡**
- Multimodal mech interp survey (2025-02) **å¹¾ä¹æ²’è¦†è“‹ speech**
- Vision æœ‰ toolkit (Prisma)ï¼Œspeech **æ²’æœ‰**
- AI Safety ç¤¾ç¾¤åš LLM interpï¼Œ**æ²’äººåš speech safety**

### Paper Ideasï¼ˆå„ªå…ˆç´šæ’åºï¼‰
1. ğŸ¥‡ **Mech Interp of Speech Understanding in Omni-LLMs** â†’ NeurIPS/ICLR
2. ğŸ¥ˆ **SpeechLens Toolkit** â†’ EMNLP Demo / Interspeech
3. ğŸ¥‰ **Audio Adversarial Ã— Mech Interp = Safety** â†’ NeurIPS SafeGenAI

### Must-Read List
- [ ] Beyond Transcription: Mech Interp in ASR (2025-08)
- [ ] Behind the Scenes: Whisper LoRA Mech Interp (2025-09)
- [ ] What Do Neurons Listen To (2026-02)
- [ ] Survey on Mech Interp for MMFMs (2025-02)
- [ ] Prisma toolkit (2025-04)
- [ ] Visual Representations inside LM (2025-10)

---

*ä¸‹æ¬¡æ›´æ–°ï¼šæ·±è®€ must-read listï¼Œè¨­è¨ˆå¯¦é©—æ–¹æ¡ˆ*
