# ðŸ§  Cycle #77 â€” 2026-02-28 14:01

## Action: learn (arXiv Feb 28 scan)

## Context
First afternoon scan of the Feb 28 batch at the expected Taipei posting time (~14:00). Last scan was cycle #76 at 13:31 (30 min ago). Two previously-unscanned papers found from the search results.

## Content

### Scan results â€” 5 queries run:
1. `mechanistic interpretability speech` â€” same 8 papers as before (AR&D, Kawamura, Maghsoudi, Zhao, Behind the Scenes, Beyond Transcription)
2. `sparse autoencoder audio` â€” same AudioSAE, Mariotte, Plantinga, Paek papers + 2 NEW entries
3. `audio language model interpretability` â€” GSRM, Bagpiper, HoliAntiSpoof (irrelevant)
4. `causal patching speech layer` â€” only 1 result (Maghsoudi brain-to-speech; no new)
5. `group sparse autoencoders multimodal` â€” arXiv:2601.20028

### New papers found (not previously scanned):

**1. TADA! â€” "Tuning Audio Diffusion Models through Activation Steering"**
- **Authors:** Staniszewski, Zaleska, Modrzejewski, Deja (Feb 12, 2026)
- **Abstract:** Uses activation patching to demonstrate that distinct semantic musical concepts (instruments, vocals, genre) are controlled by a **small localized subspace** in audio diffusion model (probably MusicGen-type). Steers model at that subspace to change output without retraining.
- **Relevance to Leo:** 
  - This is activation patching for AUDIO â€” but generative diffusion, not speech LLMs
  - Confirms that localized subspaces for semantic audio concepts exist and are steer-able
  - **Gap: no analogous patching for speech encoders (Whisper) or speech LLMs (Qwen-Audio)** â†’ Leo's space still open
  - The TADA approach (find subspace â†’ steer) is methodologically similar to SPIRIT (Track 5) but different domain (music diffusion vs speech classification/safety)
  - **Weak competitor**: works on diffusion model, not transformers; different modality (music synthesis vs speech understanding)
  - **Connection to Track 2 (AudioSAEBench)**: TADA shows steerability is real in audio; Leo's gc(F) metric = formalization of what TADA achieves empirically
- **Verdict:** SCAN (not deep-read). Adds weak corroborating evidence. Not a competitor.

**2. "Decomposing multimodal embedding spaces with group-sparse autoencoders" (arXiv:2601.20028)**
- **Authors:** Kaushik, Barch, Fanelli (Jan 27, 2026)
- **Abstract:** Group-sparse autoencoders applied to CLIP-style multimodal embeddings (vision-text). Groups features by modality origin. Claims to decompose shared vs modality-specific features.
- **Relevance to Leo:**
  - Applied to image-text, not audio
  - Group-sparse = potentially more interpretable than flat SAE; features are grouped by modality origin â†’ this is related to "audio pathway vs text pathway" attribution (Track 3)
  - **Interesting methodological connection**: Group-SAE could be applied to audio-text LALM to separate audio-specific from text-specific features â€” this could be a methodological addition to Paper B (AudioSAEBench)
  - **Gap still open**: nobody has applied group-sparse SAE to audio-text models
  - **Not a competitor** (vision-text, not speech/audio)
- **Verdict:** SCAN. Adds group-SAE as a potential method for Paper B.

### Summary
- Feb 28 arXiv batch: appears to still be posting (no truly NEW submissions with Feb 28 dates found)
- The two papers above are from Feb 12 and Jan 27 respectively â€” likely appeared in previous batch windows but were missed in prior scans
- **No new direct competitors identified**
- All 17 gaps remain open
- Leo's core gap (layer-wise causal patching of speech LLMs) remains untouched

## Connections to prior work
- TADA confirms activation patching works in audio generative models â†’ supports the general feasibility Leo wants for speech encoders
- Group-SAE (2601.20028) connects to Track 3 (audio-vs-text pathway) and Track 2 (AudioSAEBench category 5: Grounding Sensitivity)
- Both papers reinforce Paper B's value: nobody does this at the speech LLM layer, with causal evaluation

## Next
- arXiv Feb 28 batch confirmed: same papers, no new MIÃ—speech submissions today
- If Q7 synthesis threshold applies (15 deep reads, 0 experiments): next cycle should either be reflect(meta-synthesis) OR wait for Leo unblock
- Recommended: **reflect(meta-awareness)** â€” update meta-board with TADA and Group-SAE as minor methodological additions; record that gap verification is now complete for Feb 28

## Tags: #arxiv-scan #audio-diffusion #group-sae #activation-steering #gap-verification
