# ðŸ§  Cycle #75 â€” 2026-02-28 13:02
## Action: learn (Idea Gate â€” Research Idea #7: Audio T-SAE)
## Context: arXiv Feb 28 batch not yet posted (~14:00 Taipei, ~1h away). Idea #7 (Audio T-SAE, formalized cycle #72) is the newest and most time-sensitive idea (ICLR Oral attention â†’ competition risk). idea_gate.md now exists but Idea #7 has never gone through the gate. Running the gate = highest-value use of this 30-min window before arXiv arrives. Novelty scan covers 5 search queries across arXiv.

## Content

### Idea Gate Report â€” Audio T-SAE (Research Idea #7)
> Full gate per `memory/learning/idea_gate.md` protocol

**Date:** 2026-02-28 13:02  
**Idea:** "Phoneme-Aware Sparse Autoencoders for Speech Models via Temporal Contrastive Learning"  
**Source:** Cycle #72 â€” synthesized from T-SAE (Bhalla et al., ICLR 2026 Oral) + Gap #12 (Mariotte: no temporal resolution in audio SAEs)

---

#### Step 1: Idea Snapshot

**One-sentence claim:**  
We apply Temporal SAEs with multi-scale contrastive loss to Whisper/HuBERT, showing phoneme-level feature disentanglement (measured by TCS(F)) that existing i.i.d. SAEs miss.

**Target venue + deadline:**  
- Primary: INTERSPEECH 2027 (submission ~2027-03, ~13 months)  
- Alternative: ICASSP 2027 (~2026-10 deadline)  
- Backup: EACL 2027 or ACL Findings  

**Expected artifact:**  
Method paper + new metric (TCS(F) = Temporal Coherence Score) + trained Audio T-SAE on LibriSpeech

---

#### Step 2: Novelty Scan

**Queries run (5 total, all returned 0 results):**
1. "temporal sparse autoencoder audio" â†’ **0 results**
2. "phoneme sparse autoencoder speech temporal" â†’ **0 results**
3. "speech SAE contrastive learning interpretability" â†’ **0 results**
4. "temporal audio sparse autoencoder" â†’ **0 results** (cycle #74 confirmed)
5. T-SAE v2 (arXiv:2511.05541v2) full paper scan â†’ **no audio extension** (cycle #74)

**Closest papers (overlap table):**

| Paper | Year | Q (same?) | M (same family?) | O (same output?) |
|-------|------|-----------|-----------------|-----------------|
| T-SAE (Bhalla, ICLR 2026) | Oct 2025 | Partial â€” "sequential modalities" but text only | Same â€” contrastive+Matryoshka SAE | Different â€” text tokens, not phonemes |
| AudioSAE (Aparin, EACL 2026) | Feb 2026 | Partial â€” speech SAE but no temporal structure | Partial â€” TopK SAE, no contrastive | Partial â€” layer-wise but no temporal |
| Mariotte (ICASSP 2026) | Sep 2025 | Partial â€” audio SSL SAE | Partial â€” TopK SAE, no contrastive | Different â€” mean-pooled, no temporal |
| AR&D (Chowdhury, ICASSP 2026) | Feb 2026 | Partial â€” AudioLLM SAE | Partial â€” no contrastive | Different â€” neuron concept naming |
| Plantinga PD paper | 2025 | Partial â€” speech SAE | Different | Different â€” Parkinson's disease |

**Overlap assessment:**  
- Closest = T-SAE (same method family), but **question is DIFFERENT** (audio phonemes vs text tokens) and **output is DIFFERENT** (TCS(F) metric + phoneme-level feature maps vs topic/POS feature maps)  
- No paper applies contrastive loss to audio SAEs  
- No paper measures temporal coherence at phoneme-level for SAE features  

**R/Y/G Verdict: ðŸŸ¢ GREEN**  
Clear differentiation on ALL three dimensions (Q: audio phonemes vs text; M: adds multi-scale SHORT+LONG contrastive; O: TCS(F) metric + MFA phoneme boundary evaluation). The fact that T-SAE authors explicitly flag "other sequential modalities" as future work = motivated gap, but NO paper has gone there yet.

---

#### Step 3: Duplicate Risk (additional)

- T-SAE authors: no audio extension in v2 (camera-ready, Feb 25 2026), no code repo yet
- AudioSAE/Mariotte/AR&D authors: no evidence of temporal extension plans
- Risk window: ICLR 2026 Oral = high visibility â†’ may attract competitors in 3-6 months
- **Recommended action:** Monitor T-SAE citation trail monthly; if competitor appears â†’ pivot to "Audio T-SAE vs standard SAE: a comparative analysis" (faster, still novel)

---

#### Step 4: Feasibility Gate (MVE)

**Minimum Viable Experiment:**
- Train standard TopK SAE on Whisper-small layer 3 activations (LibriSpeech clean-100, 100h)
- Train Audio T-SAE on same activations with phoneme-level contrastive loss (SHORT = adjacent frames in same phoneme, negatives = adjacent frames across phoneme boundary)
- Compare TCS(F) = within-phoneme variance / across-phoneme variance for top 50 features
- Phoneme boundaries from MFA (Montreal Forced Aligner) alignments on LibriSpeech

**Prerequisites:**
- LibriSpeech audio + MFA alignments (publicly available)
- GPU for SAE training (~4-8h on one GPU for layer 3 only)
- Whisper-small (already in toolchain from whisper_hook_demo.py)
- T-SAE architecture (paper has full equations; no code yet â†’ reimplement in ~200 lines)

**Estimated time:** ~1-2 days GPU compute (needs lab desktop or NDIF)  
**Success threshold:** TCS(F) for Audio T-SAE > TCS(F) for standard SAE by â‰¥ 20% on â‰¥ 30% of top-50 features  
**Failure threshold:** TCS(F) improvement < 5% â†’ gap #12 may be harder than expected â†’ need to reframe or check phoneme boundary quality

**Result: PASS** (feasibility is realistic; main blocker is GPU access = lab desktop or NDIF, same as IIT experiment)

---

#### Step 5: Value Gate

| Criterion | Score (1-5) | Rationale |
|-----------|-------------|-----------|
| **Impact** | 4 | TCS(F) metric = novel, reusable; phoneme-aware features = useful for downstream ASR / speech editing / safety; directly extends AudioSAEBench |
| **Tractability** | 3 | Needs GPU + MFA alignments; T-SAE code doesn't exist yet (reimplement ~200 lines). 1-2 weeks compute once unblocked. |
| **Timing** | 4 | ICLR 2026 Oral visibility â†’ 3-6 month window before competitors likely. INTERSPEECH 2027 gives 13 months. |

**Total: 11/15 â†’ CONTINUE** âœ… (â‰¥10 = proceed)

**Refinement note:** Start with SHORT contrastive loss only (same vs cross phoneme boundary) â†’ prove TCS(F) improves â†’ then add LONG (utterance-level speaker consistency). Ship MVE first, don't over-engineer.

---

#### Step 6: Positioning within Portfolio

Research Idea #7 sits between Track 2 (AudioSAEBench) and Track 1 (Audio Causal Benchmark):
- **TCS(F)** = new metric for Paper B (AudioSAEBench Category 5: Temporal Structure)
- **Audio T-SAE** = model being benchmarked in Paper B
- **Relationship:** Paper B evaluates Audio T-SAE among others â†’ they are deeply intertwined
- **NEW INSIGHT:** Audio T-SAE is Paper B's "flagship model" â€” Paper B needs a model to showcase TCS(F) on; Audio T-SAE IS that model. They can be the same paper or companion papers.

**Venue Strategy:**
- If combined with Paper B â†’ NeurIPS 2026 D&B Track (same as current plan)  
- If standalone â†’ INTERSPEECH 2027 or ICASSP 2027  
- **Recommended:** Integrate TCS(F) + Audio T-SAE as the "temporal" section of Paper B (AudioSAEBench). This preserves Paper B's scope while adding a novel model + metric. Risk: scope creep. Mitigation: treat Audio T-SAE training as the Paper B Phase 2 MVP.

---

#### Summary: Idea #7 Gate Result

| Gate | Result |
|------|--------|
| Novelty | ðŸŸ¢ GREEN (0 competitors on all queries) |
| Duplicate Risk | LOW-MEDIUM (T-SAE Oral = awareness, but 0 audio extensions exist) |
| Feasibility | âœ… PASS (GPU + MFA + T-SAE re-impl, 1-2 weeks once unblocked) |
| Value | 11/15 âœ… CONTINUE |
| Portfolio fit | Integrates into Paper B as flagship model + TCS(F) metric |

**Decision: PROCEED with Audio T-SAE as Paper B's temporal module.** Priority: after Paper A (Listen Layer) experiments are running, Audio T-SAE = Paper B's highest-novelty contribution.

---

### Meta-Awareness Observation

This is the first idea to go through the full idea_gate.md protocol. Time: ~25 minutes. Output: concrete gate report with 5 search queries, overlap table, feasibility MVE, value score, portfolio positioning.

**Improvement suggestion:** Future ideas should run idea_gate.md before being added to goals.md. Currently Idea #7 was added to goals.md first (cycle #72) and gate-checked later. Proposed new rule:
> "New paper ideas â†’ idea_gate.md first â†’ then add to goals.md if GREEN/YELLOW"
> **Exception:** time-critical ideas (discovered during arXiv scan) â†’ note in progress.md with `[GATE PENDING]` tag â†’ gate within next 2 cycles.

This rule catches low-ROI ideas before they get anchored in goals.md.

## Next: Cycle #76 at ~14:00 = arXiv Feb 28 batch scan (cs.SD + cs.CL). Keyword focus: T-SAE audio, temporal SAE speech, listen layer speech LLM, grounding coefficient, audio mechanistic interp. Also: add idea_gate-first rule to SKILL.md or meta-awareness-board.md (1-line addition, reversible).
## Tags: #idea-gate #audio-T-SAE #research-idea-7 #novelty-scan #feasibility #value-gate #portfolio
