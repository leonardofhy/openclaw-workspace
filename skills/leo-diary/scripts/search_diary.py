#!/usr/bin/env python3
"""
æœå°‹ Leo æ—¥è¨˜ â€” å¢å¼·ç‰ˆ
æ”¯æ´å¤šé—œéµè© (AND/OR)ã€äººç‰©åˆ¥åã€æ—¥æœŸç¯„åœã€æ­£å‰‡è¡¨é”å¼

ç”¨æ³•ï¼š
  python3 search_diary.py æ™ºå‡±                    # åŸºæœ¬æœå°‹ï¼ˆå«åˆ¥åå±•é–‹ï¼‰
  python3 search_diary.py æ™ºå‡± æ¸¸æ³³               # AND: åŒæ™‚å‡ºç¾
  python3 search_diary.py æ™ºå‡± æ¸¸æ³³ --or          # OR: ä»»ä¸€å‡ºç¾
  python3 search_diary.py è«–æ–‡ --start 2026-01-01  # æ—¥æœŸç¯„åœ
  python3 search_diary.py "å‡Œæ™¨[3-5]é»" --regex   # æ­£å‰‡
  python3 search_diary.py æ™ºå‡± --json             # JSON è¼¸å‡ºï¼ˆä¾›è…³æœ¬ç”¨ï¼‰
  python3 search_diary.py --people                 # åˆ—å‡ºå·²çŸ¥äººç‰©åˆ¥åè¡¨
  python3 search_diary.py æ™ºå‡± --field completed   # æœå°‹ç‰¹å®šæ¬„ä½
"""
import sys
import os
import re
import json
import argparse

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from read_diary import load_diary

# â”€â”€â”€ äººç‰©åˆ¥åè¡¨ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# key = æ¨™æº–å, value = æ‰€æœ‰å¯èƒ½å‡ºç¾çš„ç¨±å‘¼
ALIASES = {
    "æ™ºå‡±": ["æ™ºå‡±", "æ™ºå‡±å“¥", "å‡±å“¥", "zhikai"],
    "æ™¨å®‰": ["æ™¨å®‰", "æ™¨å®‰å“¥", "chenan"],
    "åº·å“¥": ["åº·å“¥", "åº·", "kang"],
    "æå®æ¯…": ["æå®æ¯…", "å®æ¯…", "å®æ¯…è€å¸«", "è€å¸«", "æè€å¸«", "hungyi", "hung-yi"],
    "æ˜æ·µ": ["æ˜æ·µ", "mingyuan"],
    "æœ—è»’": ["æœ—è»’", "langxuan"],
    "Rocky": ["Rocky", "rocky"],
    "Wilson": ["Wilson", "wilson"],
    "Howard": ["Howard", "howard"],
    "David": ["David", "david"],
    "Ziya": ["Ziya", "ziya"],
    "Christine": ["Christine", "christine"],
    "Teddy": ["Teddy", "teddy"],
    "Zen": ["Zen", "zen"],
    "é™³ç¸•å„‚": ["é™³ç¸•å„‚", "ç¸•å„‚", "yunnnung", "vivian"],
    "å°ˆé¡Œç”Ÿ": ["å°ˆé¡Œç”Ÿ"],
    "åª½": ["æˆ‘åª½", "åª½åª½", "è€åª½"],
    "çˆ¸": ["æˆ‘çˆ¸", "çˆ¸çˆ¸", "è€çˆ¸"],
}

# æœå°‹æ¬„ä½æ˜ å°„
SEARCHABLE_FIELDS = {
    "diary": "diary",
    "completed": "completed",
    "all": None,  # special: search diary + completed
}


def expand_keyword(keyword: str) -> list[str]:
    """å¦‚æœé—œéµè©åŒ¹é…æŸäººçš„ä»»ä¸€åˆ¥åï¼Œå±•é–‹ç‚ºè©²äººçš„æ‰€æœ‰åˆ¥å"""
    kw_lower = keyword.lower()
    for canonical, aliases in ALIASES.items():
        if any(a.lower() == kw_lower for a in aliases):
            return aliases
    return [keyword]


def matches_text(text: str, patterns: list[str], use_regex: bool) -> list[str]:
    """å›å‚³åœ¨ text ä¸­å‘½ä¸­çš„ pattern åˆ—è¡¨"""
    hits = []
    for p in patterns:
        if use_regex:
            if re.search(p, text, re.IGNORECASE):
                hits.append(p)
        else:
            if p.lower() in text.lower():
                hits.append(p)
    return hits


def extract_context(text: str, pattern: str, context_chars: int = 80, use_regex: bool = False) -> list[str]:
    """æå–é—œéµè©å‘¨åœçš„æ–‡å­—ç‰‡æ®µ"""
    snippets = []
    if use_regex:
        for m in re.finditer(pattern, text, re.IGNORECASE):
            start = max(0, m.start() - context_chars)
            end = min(len(text), m.end() + context_chars)
            snippet = text[start:end].replace('\n', ' ')
            if start > 0:
                snippet = "â€¦" + snippet
            if end < len(text):
                snippet = snippet + "â€¦"
            snippets.append(snippet)
    else:
        p_lower = pattern.lower()
        t_lower = text.lower()
        idx = 0
        while True:
            pos = t_lower.find(p_lower, idx)
            if pos == -1:
                break
            start = max(0, pos - context_chars)
            end = min(len(text), pos + len(pattern) + context_chars)
            snippet = text[start:end].replace('\n', ' ')
            if start > 0:
                snippet = "â€¦" + snippet
            if end < len(text):
                snippet = snippet + "â€¦"
            snippets.append(snippet)
            idx = pos + 1
            if len(snippets) >= 3:
                break
    return snippets


def search(keywords: list[str], start_date=None, end_date=None,
           use_or=False, use_regex=False, context_chars=80,
           field="diary", max_results=50) -> list[dict]:
    """
    æœå°‹æ—¥è¨˜ã€‚
    keywords: æœå°‹è©åˆ—è¡¨
    use_or: True=ä»»ä¸€å‘½ä¸­å³å¯, False=å…¨éƒ¨éƒ½è¦å‘½ä¸­
    """
    entries = load_diary(start_date=start_date, end_date=end_date, has_diary_only=True)

    # å±•é–‹åˆ¥åï¼ˆé regex æ¨¡å¼ï¼‰
    all_patterns = []
    keyword_to_patterns = {}
    for kw in keywords:
        if use_regex:
            patterns = [kw]
        else:
            patterns = expand_keyword(kw)
        keyword_to_patterns[kw] = patterns
        all_patterns.extend(patterns)

    results = []
    for entry in entries:
        # æ±ºå®šæœå°‹çš„æ–‡å­—ç¯„åœ
        if field == "all":
            search_text = (entry.get("diary", "") + "\n" + entry.get("completed", ""))
        else:
            search_text = entry.get(field, "")

        if not search_text.strip():
            continue

        # å°æ¯å€‹åŸå§‹é—œéµè©ï¼Œæª¢æŸ¥å…¶ patterns æ˜¯å¦æœ‰å‘½ä¸­
        kw_hits = {}
        for kw, patterns in keyword_to_patterns.items():
            hits = matches_text(search_text, patterns, use_regex)
            if hits:
                kw_hits[kw] = hits

        # AND/OR åˆ¤æ–·
        if use_or:
            if not kw_hits:
                continue
        else:
            if len(kw_hits) < len(keywords):
                continue

        # æå– context snippets
        snippets = []
        seen_patterns = set()
        for kw, hits in kw_hits.items():
            for h in hits:
                if h not in seen_patterns:
                    seen_patterns.add(h)
                    snippets.extend(extract_context(search_text, h, context_chars, use_regex))

        results.append({
            "date": entry["date"],
            "mood": entry.get("mood", ""),
            "energy": entry.get("energy", ""),
            "matched_keywords": list(kw_hits.keys()),
            "matched_aliases": [a for hits in kw_hits.values() for a in hits],
            "snippets": snippets[:5],
            "diary_length": len(entry.get("diary", "")),
        })

        if len(results) >= max_results:
            break

    return results


def print_people():
    """åˆ—å°äººç‰©åˆ¥åè¡¨"""
    print("ğŸ“‹ å·²çŸ¥äººç‰©åˆ¥åè¡¨ï¼š\n")
    for canonical, aliases in sorted(ALIASES.items()):
        print(f"  {canonical}: {', '.join(aliases)}")
    print(f"\nå…± {len(ALIASES)} äººã€‚ç·¨è¼¯ search_diary.py çš„ ALIASES å¯æ–°å¢ã€‚")


def main():
    parser = argparse.ArgumentParser(description="æœå°‹ Leo æ—¥è¨˜")
    parser.add_argument("keywords", nargs="*", help="æœå°‹é—œéµè©ï¼ˆå¤šå€‹=ANDï¼‰")
    parser.add_argument("--or", dest="use_or", action="store_true", help="å¤šé—œéµè©ç”¨ ORï¼ˆé è¨­ ANDï¼‰")
    parser.add_argument("--regex", action="store_true", help="é—œéµè©è¦–ç‚ºæ­£å‰‡è¡¨é”å¼")
    parser.add_argument("--start", help="èµ·å§‹æ—¥æœŸ YYYY-MM-DD")
    parser.add_argument("--end", help="çµæŸæ—¥æœŸ YYYY-MM-DD")
    parser.add_argument("--context", type=int, default=80, help="å‰å¾Œæ–‡å­—æ•¸ï¼ˆé è¨­ 80ï¼‰")
    parser.add_argument("--field", choices=["diary", "completed", "all"], default="diary",
                        help="æœå°‹æ¬„ä½ï¼ˆé è¨­ diaryï¼‰")
    parser.add_argument("--max", type=int, default=50, help="æœ€å¤šå›å‚³ç­†æ•¸ï¼ˆé è¨­ 50ï¼‰")
    parser.add_argument("--json", action="store_true", help="JSON è¼¸å‡º")
    parser.add_argument("--people", action="store_true", help="åˆ—å‡ºå·²çŸ¥äººç‰©åˆ¥åè¡¨")
    parser.add_argument("--stats", action="store_true", help="åªé¡¯ç¤ºçµ±è¨ˆï¼ˆæ—¥æœŸåˆ—è¡¨+æ¬¡æ•¸ï¼‰")
    args = parser.parse_args()

    if args.people:
        print_people()
        return

    if not args.keywords:
        parser.print_help()
        sys.exit(1)

    results = search(
        keywords=args.keywords,
        start_date=args.start,
        end_date=args.end,
        use_or=args.use_or,
        use_regex=args.regex,
        context_chars=args.context,
        field=args.field,
        max_results=args.max,
    )

    if args.json:
        print(json.dumps({
            "query": args.keywords,
            "mode": "OR" if args.use_or else "AND",
            "count": len(results),
            "results": results,
        }, ensure_ascii=False, indent=2))
        return

    if args.stats:
        print(f"æ‰¾åˆ° {len(results)} ç­†åŒ…å« {'|'.join(args.keywords)} çš„æ—¥è¨˜")
        print(f"æ—¥æœŸç¯„åœï¼š{results[0]['date']} ~ {results[-1]['date']}" if results else "ç„¡çµæœ")
        if results:
            print(f"\næ—¥æœŸåˆ—è¡¨ï¼š")
            for r in results:
                print(f"  {r['date']} (å¿ƒæƒ…:{r['mood']} ç²¾åŠ›:{r['energy']})")
        return

    # äººé¡å‹å¥½è¼¸å‡º
    print(f"ğŸ” æœå°‹ï¼š{'|'.join(args.keywords)}ï¼ˆ{'OR' if args.use_or else 'AND'}æ¨¡å¼ï¼‰")
    if args.start or args.end:
        print(f"ğŸ“… ç¯„åœï¼š{args.start or '...'} ~ {args.end or '...'}")
    print(f"ğŸ“Š æ‰¾åˆ° {len(results)} ç­†\n")

    for r in results:
        matched_info = ""
        aliases_used = set(r["matched_aliases"]) - set(r["matched_keywords"])
        if aliases_used:
            matched_info = f" [åˆ¥åå‘½ä¸­: {', '.join(aliases_used)}]"

        print(f"ğŸ“… {r['date']} (å¿ƒæƒ…:{r['mood']}/5 ç²¾åŠ›:{r['energy']}/5){matched_info}")
        for s in r["snippets"]:
            print(f"   â†’ {s[:300]}")
        print()


if __name__ == "__main__":
    main()
