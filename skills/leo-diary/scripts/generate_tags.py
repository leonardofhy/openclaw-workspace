#!/usr/bin/env python3
"""
æ—¥è¨˜æ¨™ç±¤æå–å™¨ï¼ˆç´” Pythonï¼Œä¸ä¾è³´ LLMï¼‰
ç”¨é€”ï¼šæ‰¹é‡å›å¡«æ­·å²æ¨™ç±¤ / ä½œç‚º LLM æ¨™ç±¤çš„ fallback

ç”¨æ³•ï¼š
  python3 generate_tags.py                    # è™•ç†æ‰€æœ‰æ—¥è¨˜
  python3 generate_tags.py --date 2026-02-22  # è™•ç†æŒ‡å®šæ—¥æœŸ
  python3 generate_tags.py --recent 7         # æœ€è¿‘ 7 å¤©
  python3 generate_tags.py --dry-run          # é è¦½ä¸å¯«å…¥
"""
import json
import os
import sys
import re
import glob
import argparse
from datetime import datetime, timedelta
from collections import Counter

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

MEMORY_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "..", "..", "..", "memory")
TAGS_DIR = os.path.join(MEMORY_DIR, "tags")

# Diary metrics cache (loaded once from Google Sheets / CSV)
_diary_metrics_cache = None

def _load_diary_metrics():
    """Load mood/energy from diary source (Sheets or CSV). Cached."""
    global _diary_metrics_cache
    if _diary_metrics_cache is not None:
        return _diary_metrics_cache
    try:
        from read_diary import load_diary
        entries = load_diary(has_diary_only=False)
        _diary_metrics_cache = {}
        for e in entries:
            d = e.get('date', '')
            if d and d not in _diary_metrics_cache:
                metrics = {}
                try:
                    m = int(e.get('mood', ''))
                    if 1 <= m <= 5:
                        metrics['mood'] = m
                except (ValueError, TypeError):
                    pass
                try:
                    en = int(e.get('energy', ''))
                    if 1 <= en <= 5:
                        metrics['energy'] = en
                except (ValueError, TypeError):
                    pass
                if metrics:
                    _diary_metrics_cache[d] = metrics
    except Exception as ex:
        print(f"[warn] Could not load diary metrics: {ex}", file=sys.stderr)
        _diary_metrics_cache = {}
    return _diary_metrics_cache

# â”€â”€â”€ äººç‰©åˆ¥åè¡¨ï¼ˆèˆ‡ search_diary.py åŒæ­¥ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PEOPLE_ALIASES = {
    "æ™ºå‡±": ["æ™ºå‡±", "æ™ºå‡±å“¥", "å‡±å“¥", "zhikai"],
    "æ™¨å®‰": ["æ™¨å®‰", "æ™¨å®‰å“¥", "chenan"],
    "åº·å“¥": ["åº·å“¥", "kang"],
    "æå®æ¯…": ["æå®æ¯…", "å®æ¯…", "å®æ¯…è€å¸«", "æè€å¸«", "hungyi", "hung-yi"],
    "æ˜æ·µ": ["æ˜æ·µ", "mingyuan"],
    "æœ—è»’": ["æœ—è»’", "langxuan"],
    "Rocky": ["Rocky", "rocky"],
    "Wilson": ["Wilson", "wilson"],
    "Howard": ["Howard", "howard"],
    "David": ["David", "david"],
    "Ziya": ["Ziya", "ziya"],
    "Christine": ["Christine", "christine"],
    "Teddy": ["Teddy", "teddy"],
    "Zen": ["Zen", "zen"],
    "é™³ç¸•å„‚": ["é™³ç¸•å„‚", "ç¸•å„‚", "yunnnung", "vivian"],
    "å°ˆé¡Œç”Ÿ": ["å°ˆé¡Œç”Ÿ"],
    "åª½": ["æˆ‘åª½", "åª½åª½", "è€åª½"],
    "çˆ¸": ["æˆ‘çˆ¸", "çˆ¸çˆ¸", "è€çˆ¸"],
}

# â”€â”€â”€ ä¸»é¡Œé—œéµè© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOPIC_KEYWORDS = {
    "AudioMatters": ["audiomatters", "audio matters", "benchmark", "èªéŸ³è©•ä¼°"],
    "ç ”ç©¶/å¯¦é©—": ["å¯¦é©—", "è·‘å¯¦é©—", "æ¨¡å‹", "training", "dataset", "è«–æ–‡", "paper"],
    "ä¸Šèª²": ["ä¸Šèª²", "lecture", "èª²ç¨‹", "æ•™å®¤", "å°ˆé¡Œè¨è«–", "æ·±åº¦å­¸ç¿’", "å¼·åŒ–å­¸ç¿’"],
    "æ¸¸æ³³": ["æ¸¸æ³³", "æ³³æ± ", "æ¸¸äº†"],
    "é‹å‹•": ["å¥èº«", "ä¿¯è‡¥æ’", "è·‘æ­¥", "é‹å‹•"],
    "ç¤¾äº¤/èšé¤": ["lab dinner", "åƒé£¯", "èšé¤", "å–é…’", "èŠå¤©"],
    "LOL": ["lol", "LOL", "è‹±é›„è¯ç›Ÿ"],
    "å‹•ç•«": ["å‹•ç•«", "anime", "çœ‹ç•ª", "è¿½ç•ª", "æ–°ç•ª", "ç•ªåŠ‡"],
    "è¥¿æ´‹æ£‹": ["è¥¿æ´‹æ£‹", "chess", "lichess"],
    "NTUAIS": ["ntuais", "NTU AI Safety", "ai safety"],
    "çå­¸é‡‘": ["çå­¸é‡‘", "scholarship"],
    "è¡Œæ”¿": ["å±…ç•™è­‰", "ç°½è­‰", "visa", "æˆ¶æ”¿", "éŠ€è¡Œ", "é–‹æˆ¶"],
    "Todoist": ["todoist"],
    "OpenClaw": ["openclaw", "cron", "little leo", "bot"],
    "Duolingo": ["duolingo"],
    "èºè„ç²‰": ["èºè„ç²‰", "èºè›³ç²‰"],
    "éº¥ç•¶å‹": ["éº¥ç•¶å‹", "mcdonald"],
    "å¯¦é©—å®¤": ["å¯¦é©—å®¤", "lab", "531", "552"],
    "ç¡çœ è­°é¡Œ": ["å¤±çœ ", "ç¡ä¸è‘—", "ç†¬å¤œ", "æ™šç¡", "ä½œæ¯äº‚"],
    "ç”Ÿç—…": ["æ„Ÿå†’", "ç™¼ç‡’", "å’³å—½", "å–‰åš¨ç—›", "é ­ç—›", "ç”Ÿç—…", "çœ‹é†«ç”Ÿ"],
    "é¦¬ä¾†è¥¿äº": ["é¦¬ä¾†è¥¿äº", "malaysia", "æ–°å±±", "å›é¦¬", "å¤§é¦¬", "é¦¬ä¾†"],
    "Compass": ["compass", "ç‡ŸéšŠ"],
    "email": ["email", "å¯„ä¿¡", "å›ä¿¡"],
    "è¨˜å¸³": ["è¨˜å¸³", "èŠ±è²»", "æ”¯å‡º", "å­˜æ¬¾"],
}

# â”€â”€â”€ æ™šç¡åˆ¤å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
LATE_SLEEP_PATTERNS = [
    r"å‡Œæ™¨[2-7]é»",
    r"[2-7]é».*æ‰ç¡",
    r"[2-7]é».*å…¥ç¡",
    r"ç†¬å¤œ",
    r"å¾ˆæ™š.*ç¡",
]


def extract_people(text: str) -> list[str]:
    """æå–æåŠçš„äººç‰©"""
    found = []
    for canonical, aliases in PEOPLE_ALIASES.items():
        for alias in aliases:
            if alias in text:
                found.append(canonical)
                break
    return sorted(set(found))


def extract_topics(text: str) -> list[str]:
    """æå–ä¸»é¡Œæ¨™ç±¤"""
    text_lower = text.lower()
    found = []
    for topic, keywords in TOPIC_KEYWORDS.items():
        for kw in keywords:
            if kw.lower() in text_lower:
                found.append(topic)
                break
    return sorted(set(found))


def detect_late_sleep(text: str) -> bool:
    """åµæ¸¬æ˜¯å¦æåˆ°æ™šç¡"""
    for pat in LATE_SLEEP_PATTERNS:
        if re.search(pat, text):
            return True
    return False


def extract_metrics_from_header(content: str) -> dict:
    """å¾ memory/*.md çš„ YAML-like header æå–æŒ‡æ¨™"""
    metrics = {}
    # å˜—è©¦æŠ“ mood/energy/sleep ç­‰ (æ ¼å¼ä¸å›ºå®šï¼Œç›¡åŠ›è€Œç‚º)
    mood_m = re.search(r"å¿ƒæƒ…[ï¼š:]\s*(\d)", content[:500])
    energy_m = re.search(r"ç²¾åŠ›[ï¼š:]\s*(\d)", content[:500])
    if mood_m:
        metrics["mood"] = int(mood_m.group(1))
    if energy_m:
        metrics["energy"] = int(energy_m.group(1))
    return metrics


def generate_tag(date: str, content: str) -> dict:
    """ç‚ºä¸€ç¯‡æ—¥è¨˜ç”Ÿæˆæ¨™ç±¤"""
    tag = {
        "date": date,
        "people": extract_people(content),
        "topics": extract_topics(content),
        "late_sleep": detect_late_sleep(content),
        "diary_chars": len(content),
        "method": "python-rules",  # å€åˆ† LLM ç”Ÿæˆ vs ç´”è¦å‰‡
    }

    # Metrics: try diary source first (accurate), fall back to header parsing
    diary_metrics = _load_diary_metrics().get(date, {})
    if diary_metrics:
        tag["metrics"] = diary_metrics
    else:
        header_metrics = extract_metrics_from_header(content)
        if header_metrics:
            tag["metrics"] = header_metrics

    return tag


def process_diary_file(filepath: str) -> tuple[str, dict] | None:
    """è™•ç†ä¸€å€‹ memory/YYYY-MM-DD.md æª”æ¡ˆ"""
    basename = os.path.basename(filepath)
    date_match = re.match(r"(\d{4}-\d{2}-\d{2})\.md$", basename)
    if not date_match:
        return None

    date = date_match.group(1)
    with open(filepath, "r", encoding="utf-8") as f:
        content = f.read()

    if len(content.strip()) < 50:  # å¤ªçŸ­çš„å¿½ç•¥
        return None

    return date, generate_tag(date, content)


def main():
    parser = argparse.ArgumentParser(description="æ—¥è¨˜æ¨™ç±¤æå–å™¨")
    parser.add_argument("--date", help="æŒ‡å®šæ—¥æœŸ YYYY-MM-DD")
    parser.add_argument("--recent", type=int, help="æœ€è¿‘ N å¤©")
    parser.add_argument("--dry-run", action="store_true", help="é è¦½ä¸å¯«å…¥")
    parser.add_argument("--force", action="store_true", help="è¦†è“‹å·²æœ‰æ¨™ç±¤")
    parser.add_argument("--stats", action="store_true", help="åªé¡¯ç¤ºçµ±è¨ˆ")
    args = parser.parse_args()

    os.makedirs(TAGS_DIR, exist_ok=True)

    # æ”¶é›†è¦è™•ç†çš„æª”æ¡ˆ
    if args.date:
        files = [os.path.join(MEMORY_DIR, f"{args.date}.md")]
        files = [f for f in files if os.path.exists(f)]
    elif args.recent:
        today = datetime.now()
        dates = [(today - timedelta(days=i)).strftime("%Y-%m-%d") for i in range(args.recent)]
        files = [os.path.join(MEMORY_DIR, f"{d}.md") for d in dates]
        files = [f for f in files if os.path.exists(f)]
    else:
        files = sorted(glob.glob(os.path.join(MEMORY_DIR, "????-??-??.md")))

    processed = 0
    skipped = 0
    people_counter = Counter()
    topic_counter = Counter()

    for filepath in files:
        result = process_diary_file(filepath)
        if result is None:
            continue

        date, tag = result
        tag_path = os.path.join(TAGS_DIR, f"{date}.json")

        # è·³éå·²æœ‰ LLM æ¨™ç±¤ï¼ˆé™¤é forceï¼‰
        if os.path.exists(tag_path) and not args.force:
            with open(tag_path, "r") as f:
                existing = json.load(f)
            if existing.get("method") == "llm" and not args.force:
                skipped += 1
                continue
            if not args.force:
                skipped += 1
                continue

        # çµ±è¨ˆ
        for p in tag["people"]:
            people_counter[p] += 1
        for t in tag["topics"]:
            topic_counter[t] += 1

        if not args.dry_run:
            with open(tag_path, "w", encoding="utf-8") as f:
                json.dump(tag, f, ensure_ascii=False, indent=2)

        processed += 1

    # è¼¸å‡º
    if args.stats or args.dry_run:
        print(f"ğŸ“Š æ¨™ç±¤çµ±è¨ˆï¼š")
        print(f"   è™•ç†ï¼š{processed} ç­†  è·³éï¼š{skipped} ç­†\n")

        if people_counter:
            print(f"ğŸ‘¥ äººç‰©å‡ºç¾æ¬¡æ•¸ (top 15):")
            for name, count in people_counter.most_common(15):
                bar = "â–ˆ" * min(count, 40)
                print(f"   {name:8s} {count:3d} {bar}")

        print()
        if topic_counter:
            print(f"ğŸ“‹ ä¸»é¡Œå‡ºç¾æ¬¡æ•¸ (top 15):")
            for topic, count in topic_counter.most_common(15):
                bar = "â–ˆ" * min(count, 40)
                print(f"   {topic:12s} {count:3d} {bar}")

        if not args.dry_run:
            print(f"\nâœ… å·²å¯«å…¥ {processed} å€‹æ¨™ç±¤åˆ° {TAGS_DIR}/")
    else:
        print(f"âœ… å·²ç”Ÿæˆ {processed} å€‹æ¨™ç±¤ï¼Œè·³é {skipped} å€‹ï¼ˆå·²å­˜åœ¨ï¼‰")


if __name__ == "__main__":
    main()
